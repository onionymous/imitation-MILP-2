# SCIP version 5.0.0

# branching score function ('s'um, 'p'roduct, 'q'uotient)
# [type: char, advanced: TRUE, range: {spq}, default: p]
branching/scorefunc = p

# branching score factor to weigh downward and upward gain prediction in sum score function
# [type: real, advanced: TRUE, range: [0,1], default: 0.167]
branching/scorefac = 0.167

# should branching on binary variables be preferred?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
branching/preferbinary = FALSE

# minimal relative distance of branching point to bounds when branching on a continuous variable
# [type: real, advanced: FALSE, range: [0,0.5], default: 0.2]
branching/clamp = 0.2

# strategy for normalization of LP gain when updating pseudocosts of continuous variables (divide by movement of 'l'p value, reduction in 'd'omain width, or reduction in domain width of 's'ibling)
# [type: char, advanced: FALSE, range: {dls}, default: s]
branching/lpgainnormalize = s

# should updating pseudo costs for continuous variables be delayed to the time after separation?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
branching/delaypscostupdate = TRUE

# should pseudo costs be updated also in diving and probing mode?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
branching/divingpscost = TRUE

# should all strong branching children be regarded even if one is detected to be infeasible? (only with propagation)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/forceallchildren = FALSE

# child node to be regarded first during strong branching (only with propagation): 'u'p child, 'd'own child, 'h'istory-based, or 'a'utomatic
# [type: char, advanced: TRUE, range: {aduh}, default: a]
branching/firstsbchild = a

# should LP solutions during strong branching with propagation be checked for feasibility?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/checksol = TRUE

# should LP solutions during strong branching with propagation be rounded? (only when checksbsol=TRUE)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/roundsbsol = TRUE

# score adjustment near zero by adding epsilon (TRUE) or using maximum (FALSE)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/sumadjustscore = FALSE

# should automatic tree compression after the presolving be enabled?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
compression/enable = FALSE

# should conflict analysis be enabled?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
conflict/enable = TRUE

# should conflicts based on an old cutoff bound be removed from the conflict pool after improving the primal bound?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/cleanboundexceedings = TRUE

# should propagation conflict analysis be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
conflict/useprop = TRUE

# should infeasible LP conflict analysis be used? ('o'ff, 'c'onflict graph, 'd'ual ray, 'b'oth conflict graph and dual ray)
# [type: char, advanced: FALSE, range: {ocdb}, default: b]
conflict/useinflp = b

# should bound exceeding LP conflict analysis be used? ('o'ff, 'c'onflict graph, 'd'ual ray, 'b'oth conflict graph and dual ray)
# [type: char, advanced: FALSE, range: {ocdb}, default: b]
conflict/useboundlp = b

# should infeasible/bound exceeding strong branching conflict analysis be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
conflict/usesb = TRUE

# should pseudo solution conflict analysis be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
conflict/usepseudo = TRUE

# maximal fraction of variables involved in a conflict constraint
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.15]
conflict/maxvarsfac = 0.15

# minimal absolute maximum of variables involved in a conflict constraint
# [type: int, advanced: TRUE, range: [0,2147483647], default: 0]
conflict/minmaxvars = 0

# maximal number of LP resolving loops during conflict analysis (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 2]
conflict/maxlploops = 2

# maximal number of LP iterations in each LP resolving loop (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10]
conflict/lpiterations = 10

# number of depth levels up to which first UIP's are used in conflict analysis (-1: use All-FirstUIP rule)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
conflict/fuiplevels = -1

# maximal number of intermediate conflict constraints generated in conflict graph (-1: use every intermediate constraint)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
conflict/interconss = -1

# number of depth levels up to which UIP reconvergence constraints are generated (-1: generate reconvergence constraints in all depth levels)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
conflict/reconvlevels = -1

# maximal number of conflict constraints accepted at an infeasible node (-1: use all generated conflict constraints)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10]
conflict/maxconss = 10

# maximal size of conflict store (-1: auto, 0: disable storage)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10000]
conflict/maxstoresize = 10000

# should binary conflicts be preferred?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
conflict/preferbinary = FALSE

# prefer infeasibility proof to boundexceeding proof
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/prefinfproof = TRUE

# should conflict constraints be generated that are only valid locally?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/allowlocal = TRUE

# should conflict constraints be attached only to the local subtree where they can be useful?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
conflict/settlelocal = FALSE

# should earlier nodes be repropagated in order to replace branching decisions by deductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/repropagate = TRUE

# should constraints be kept for repropagation even if they are too long?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/keepreprop = TRUE

# should the conflict constraints be separated?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/separate = TRUE

# should the conflict constraints be subject to aging?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/dynamic = TRUE

# should the conflict's relaxations be subject to LP aging and cleanup?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/removable = TRUE

# score factor for depth level in bound relaxation heuristic
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1]
conflict/graph/depthscorefac = 1

# score factor for impact on acticity in bound relaxation heuristic
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1]
conflict/proofscorefac = 1

# score factor for up locks in bound relaxation heuristic
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0]
conflict/uplockscorefac = 0

# score factor for down locks in bound relaxation heuristic
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0]
conflict/downlockscorefac = 0

# factor to decrease importance of variables' earlier conflict scores
# [type: real, advanced: TRUE, range: [1e-06,1], default: 0.98]
conflict/scorefac = 0.98

# number of successful conflict analysis calls that trigger a restart (0: disable conflict restarts)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
conflict/restartnum = 0

# factor to increase restartnum with after each restart
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 1.5]
conflict/restartfac = 1.5

# should relaxed bounds be ignored?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
conflict/ignorerelaxedbd = FALSE

# maximal number of variables to try to detect global bound implications and shorten the whole conflict set (0: disabled)
# [type: int, advanced: TRUE, range: [0,2147483647], default: 250]
conflict/maxvarsdetectimpliedbounds = 250

# try to shorten the whole conflict set or terminate early (depending on the 'maxvarsdetectimpliedbounds' parameter)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
conflict/fullshortenconflict = TRUE

# the weight the VSIDS score is weight by updating the VSIDS for a variable if it is part of a conflict
# [type: real, advanced: FALSE, range: [0,1], default: 0]
conflict/conflictweight = 0

# the weight the VSIDS score is weight by updating the VSIDS for a variable if it is part of a conflict graph
# [type: real, advanced: FALSE, range: [0,1], default: 1]
conflict/conflictgraphweight = 1

# minimal improvement of primal bound to remove conflicts based on a previous incumbent
# [type: real, advanced: TRUE, range: [0,1], default: 0.05]
conflict/minimprove = 0.05

# weight of the size of a conflict used in score calculation
# [type: real, advanced: TRUE, range: [0,1], default: 0.001]
conflict/weightsize = 0.001

# weight of the repropagation depth of a conflict used in score calculation
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
conflict/weightrepropdepth = 0.1

# weight of the valid depth of a conflict used in score calculation
# [type: real, advanced: TRUE, range: [0,1], default: 1]
conflict/weightvaliddepth = 1

# apply cut generating functions to construct alternative proofs
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
conflict/sepaaltproofs = FALSE

# maximum age an unnecessary constraint can reach before it is deleted (0: dynamic, -1: keep all constraints)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 0]
constraints/agelimit = 0

# age of a constraint after which it is marked obsolete (0: dynamic, -1 do not mark constraints obsolete)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/obsoleteage = -1

# should enforcement of pseudo solution be disabled?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/disableenfops = FALSE

# verbosity level of output
# [type: int, advanced: FALSE, range: [0,5], default: 4]
display/verblevel = 0

# maximal number of characters in a node information line
# [type: int, advanced: FALSE, range: [0,2147483647], default: 139]
display/width = 139

# frequency for displaying node information lines
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 100]
display/freq = 100

# frequency for displaying header lines (every n'th node information line)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 15]
display/headerfreq = 15

# should the LP solver display status messages?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
display/lpinfo = FALSE

# display all violations for a given start solution / the best solution after the solving process?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
display/allviols = FALSE

# should statistics be collected for variable domain value pairs?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
history/valuebased = FALSE

# should variable histories be merged from sub-SCIPs whenever possible?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
history/allowmerge = FALSE

# should variable histories be transferred to initialize SCIP copies?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
history/allowtransfer = FALSE

# maximal time in seconds to run
# [type: real, advanced: FALSE, range: [0,1e+20], default: 1e+20]
limits/time = 600

# maximal number of nodes to process (-1: no limit)
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: -1]
limits/nodes = -1

# maximal number of total nodes (incl. restarts) to process (-1: no limit)
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: -1]
limits/totalnodes = -1

# solving stops, if the given number of nodes was processed since the last improvement of the primal solution value (-1: no limit)
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: -1]
limits/stallnodes = -1

# maximal memory usage in MB; reported memory usage is lower than real memory usage!
# [type: real, advanced: FALSE, range: [0,8796093022208], default: 8796093022208]
limits/memory = 8796093022208

# solving stops, if the relative gap = |primal - dual|/MIN(|dual|,|primal|) is below the given value
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 0]
limits/gap = 0

# solving stops, if the absolute gap = |primalbound - dualbound| is below the given value
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 0]
limits/absgap = 0

# solving stops, if the given number of solutions were found (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
limits/solutions = -1

# solving stops, if the given number of solution improvements were found (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
limits/bestsol = -1

# maximal number of solutions to store in the solution storage
# [type: int, advanced: FALSE, range: [1,2147483647], default: 100]
limits/maxsol = 100

# maximal number of solutions candidates to store in the solution storage of the original problem
# [type: int, advanced: FALSE, range: [0,2147483647], default: 10]
limits/maxorigsol = 10

# solving stops, if the given number of restarts was triggered (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
limits/restarts = -1

# if solve exceeds this number of nodes for the first time, an automatic restart is triggered (-1: no automatic restart)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
limits/autorestartnodes = -1

# frequency for solving LP at the nodes (-1: never; 0: only root LP)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
lp/solvefreq = 1

# iteration limit for each single LP solve (-1: no limit)
# [type: longint, advanced: TRUE, range: [-1,9223372036854775807], default: -1]
lp/iterlim = -1

# iteration limit for initial root LP solve (-1: no limit)
# [type: longint, advanced: TRUE, range: [-1,9223372036854775807], default: -1]
lp/rootiterlim = -1

# maximal depth for solving LP at the nodes (-1: no depth limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
lp/solvedepth = -1

# LP algorithm for solving initial LP relaxations (automatic 's'implex, 'p'rimal simplex, 'd'ual simplex, 'b'arrier, barrier with 'c'rossover)
# [type: char, advanced: FALSE, range: {spdbc}, default: s]
lp/initalgorithm = s

# LP algorithm for resolving LP relaxations if a starting basis exists (automatic 's'implex, 'p'rimal simplex, 'd'ual simplex, 'b'arrier, barrier with 'c'rossover)
# [type: char, advanced: FALSE, range: {spdbc}, default: s]
lp/resolvealgorithm = s

# LP pricing strategy ('l'pi default, 'a'uto, 'f'ull pricing, 'p'artial, 's'teepest edge pricing, 'q'uickstart steepest edge pricing, 'd'evex pricing)
# [type: char, advanced: FALSE, range: {lafpsqd}, default: l]
lp/pricing = l

# should lp state be cleared at the end of probing mode when lp was initially unsolved, e.g., when called right after presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/clearinitialprobinglp = TRUE

# should the LP be resolved to restore the state at start of diving (if FALSE we buffer the solution values)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/resolverestore = FALSE

# should the buffers for storing LP solution values during diving be freed at end of diving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/freesolvalbuffers = FALSE

# maximum age a dynamic column can reach before it is deleted from the LP (-1: don't delete columns due to aging)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10]
lp/colagelimit = 10

# maximum age a dynamic row can reach before it is deleted from the LP (-1: don't delete rows due to aging)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10]
lp/rowagelimit = 10

# should new non-basic columns be removed after LP solving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/cleanupcols = FALSE

# should new non-basic columns be removed after root LP solving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/cleanupcolsroot = FALSE

# should new basic rows be removed after LP solving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/cleanuprows = TRUE

# should new basic rows be removed after root LP solving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/cleanuprowsroot = TRUE

# should LP solver's return status be checked for stability?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/checkstability = TRUE

# maximum condition number of LP basis counted as stable (-1.0: no limit)
# [type: real, advanced: TRUE, range: [-1,1.79769313486232e+308], default: -1]
lp/conditionlimit = -1

# should LP solutions be checked for primal feasibility, resolving LP when numerical troubles occur?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/checkprimfeas = TRUE

# should LP solutions be checked for dual feasibility, resolving LP when numerical troubles occur?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/checkdualfeas = TRUE

# which FASTMIP setting of LP solver should be used? 0: off, 1: low
# [type: int, advanced: TRUE, range: [0,1], default: 1]
lp/fastmip = 1

# LP scaling (0: none, 1: normal, 2: aggressive)
# [type: int, advanced: TRUE, range: [0,2], default: 1]
lp/scaling = 1

# should presolving of LP solver be used?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/presolving = TRUE

# should the lexicographic dual algorithm be used?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/lexdualalgo = FALSE

# should the lexicographic dual algorithm be applied only at the root node
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/lexdualrootonly = TRUE

# maximum number of rounds in the lexicographic dual algorithm (-1: unbounded)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 2]
lp/lexdualmaxrounds = 2

# choose fractional basic variables in lexicographic dual algorithm?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
lp/lexdualbasic = FALSE

# turn on the lex dual algorithm only when stalling?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
lp/lexdualstalling = TRUE

# disable the cutoff bound in the LP solver? (0: enabled, 1: disabled, 2: auto)
# [type: int, advanced: TRUE, range: [0,2], default: 2]
lp/disablecutoff = 2

# simplex algorithm shall use row representation of the basis if number of rows divided by number of columns exceeds this value (-1.0 to disable row representation)
# [type: real, advanced: TRUE, range: [-1,1.79769313486232e+308], default: 1.2]
lp/rowrepswitch = 1.2

# number of threads used for solving the LP (0: automatic)
# [type: int, advanced: TRUE, range: [0,64], default: 0]
lp/threads = 0

# factor of average LP iterations that is used as LP iteration limit for LP resolve (-1: unlimited)
# [type: real, advanced: TRUE, range: [-1,1.79769313486232e+308], default: -1]
lp/resolveiterfac = -1

# minimum number of iterations that are allowed for LP resolve
# [type: int, advanced: TRUE, range: [1,2147483647], default: 1000]
lp/resolveitermin = 1000

# LP solution polishing method (0: disabled, 1: only root, 2: always, 3: auto)
# [type: int, advanced: TRUE, range: [0,3], default: 3]
lp/solutionpolishing = 3

# LP refactorization interval (0: auto)
# [type: int, advanced: TRUE, range: [0,2147483647], default: 0]
lp/refactorinterval = 0

# solver to use for solving NLPs; leave empty to select NLPI with highest priority
# [type: string, advanced: FALSE, default: ""]
nlp/solver = ""

# should the NLP relaxation be always disabled (also for NLPs/MINLPs)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
nlp/disable = FALSE

# fraction of maximal memory usage resulting in switch to memory saving mode
# [type: real, advanced: FALSE, range: [0,1], default: 0.8]
memory/savefac = 0.8

# memory growing factor for dynamically allocated arrays
# [type: real, advanced: TRUE, range: [1,10], default: 1.2]
memory/arraygrowfac = 1.2

# initial size of dynamically allocated arrays
# [type: int, advanced: TRUE, range: [0,2147483647], default: 4]
memory/arraygrowinit = 4

# memory growing factor for tree array
# [type: real, advanced: TRUE, range: [1,10], default: 2]
memory/treegrowfac = 2

# initial size of tree array
# [type: int, advanced: TRUE, range: [0,2147483647], default: 65536]
memory/treegrowinit = 65536

# memory growing factor for path array
# [type: real, advanced: TRUE, range: [1,10], default: 2]
memory/pathgrowfac = 2

# initial size of path array
# [type: int, advanced: TRUE, range: [0,2147483647], default: 256]
memory/pathgrowinit = 256

# should the CTRL-C interrupt be caught by SCIP?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/catchctrlc = TRUE

# should a hashtable be used to map from variable names to variables?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/usevartable = TRUE

# should a hashtable be used to map from constraint names to constraints?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/useconstable = TRUE

# should smaller hashtables be used? yields better performance for small problems with about 100 variables
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
misc/usesmalltables = FALSE

# should the statistics be reset if the transformed problem is freed (in case of a Benders decomposition this parameter should be set to FALSE)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/resetstat = TRUE

# should only solutions be checked which improve the primal bound
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
misc/improvingsols = FALSE

# should the reason be printed if a given start solution is infeasible
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/printreason = TRUE

# should the usage of external memory be estimated?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/estimexternmem = TRUE

# should SCIP try to transfer original solutions to the transformed space (after presolving)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/transorigsols = TRUE

# should SCIP try to transfer transformed solutions to the original space (after solving)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/transsolsorig = TRUE

# should SCIP calculate the primal dual integral value?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/calcintegral = TRUE

# should SCIP try to remove infinite fixings from solutions copied to the solution store?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
misc/finitesolutionstore = FALSE

# should the best solution be transformed to the orignal space and be output in command line run?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/outputorigsol = TRUE

# should dual reductions in propagation methods and presolver be allowed?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/allowdualreds = TRUE

# should propagation to the current objective be allowed in propagation methods?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
misc/allowobjprop = TRUE

# objective value for reference purposes
# [type: real, advanced: FALSE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1e+99]
misc/referencevalue = 1e+99

# used symmetry handling technique (0: off; 1: polyhedral; 2: orbital fixing)
# [type: int, advanced: FALSE, range: [0,2], default: 2]
misc/usesymmetry = 2

# global shift of all random seeds in the plugins and the LP random seed
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
randomization/randomseedshift = 0

# seed value for permuting the problem after reading/transformation (0: no permutation)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
randomization/permutationseed = 0

# should order of constraints be permuted (depends on permutationseed)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
randomization/permuteconss = TRUE

# should order of variables be permuted (depends on permutationseed)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
randomization/permutevars = FALSE

# random seed for LP solver, e.g. for perturbations in the simplex (0: LP default)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
randomization/lpseed = 0

# child selection rule ('d'own, 'u'p, 'p'seudo costs, 'i'nference, 'l'p value, 'r'oot LP value difference, 'h'ybrid inference/root LP value difference)
# [type: char, advanced: FALSE, range: {dupilrh}, default: h]
nodeselection/childsel = h

# values larger than this are considered infinity
# [type: real, advanced: FALSE, range: [10000000000,1e+98], default: 1e+20]
numerics/infinity = 1e+20

# absolute values smaller than this are considered zero
# [type: real, advanced: FALSE, range: [1e-20,0.001], default: 1e-09]
numerics/epsilon = 1e-09

# absolute values of sums smaller than this are considered zero
# [type: real, advanced: FALSE, range: [1e-17,0.001], default: 1e-06]
numerics/sumepsilon = 1e-06

# feasibility tolerance for constraints
# [type: real, advanced: FALSE, range: [1e-17,0.001], default: 1e-06]
numerics/feastol = 1e-06

# feasibility tolerance factor; for checking the feasibility of the best solution
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 1]
numerics/checkfeastolfac = 1

# primal feasibility tolerance of LP solver
# [type: real, advanced: FALSE, range: [1e-17,0.001], default: 1e-06]
numerics/lpfeastol = 1e-06

# feasibility tolerance for reduced costs in LP solution
# [type: real, advanced: FALSE, range: [1e-17,0.001], default: 1e-07]
numerics/dualfeastol = 1e-07

# LP convergence tolerance used in barrier algorithm
# [type: real, advanced: TRUE, range: [1e-17,0.001], default: 1e-10]
numerics/barrierconvtol = 1e-10

# minimal relative improve for strengthening bounds
# [type: real, advanced: TRUE, range: [1e-17,1e+98], default: 0.05]
numerics/boundstreps = 0.05

# minimal variable distance value to use for branching pseudo cost updates
# [type: real, advanced: TRUE, range: [1e-17,1], default: 0.1]
numerics/pseudocosteps = 0.1

# minimal objective distance value to use for branching pseudo cost updates
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.0001]
numerics/pseudocostdelta = 0.0001

# minimal decrease factor that causes the recomputation of a value (e.g., pseudo objective) instead of an update
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 10000000]
numerics/recomputefac = 10000000

# values larger than this are considered huge and should be handled separately (e.g., in activity computation)
# [type: real, advanced: TRUE, range: [0,1e+98], default: 1e+15]
numerics/hugeval = 1e+15

# maximal number of presolving rounds (-1: unlimited, 0: off)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/maxrounds = -1

# abort presolve, if at most this fraction of the problem was changed in last presolve round
# [type: real, advanced: TRUE, range: [0,1], default: 0.0008]
presolving/abortfac = 0.0008

# maximal number of restarts (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/maxrestarts = -1

# fraction of integer variables that were fixed in the root node triggering a restart with preprocessing after root node evaluation
# [type: real, advanced: TRUE, range: [0,1], default: 0.025]
presolving/restartfac = 0.025

# fraction of integer variables that were fixed in the root node triggering an immediate restart with preprocessing
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
presolving/immrestartfac = 0.1

# fraction of integer variables that were globally fixed during the solving process triggering a restart with preprocessing
# [type: real, advanced: TRUE, range: [0,1], default: 1]
presolving/subrestartfac = 1

# minimal fraction of integer variables removed after restart to allow for an additional restart
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
presolving/restartminred = 0.1

# should multi-aggregation of variables be forbidden?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/donotmultaggr = FALSE

# should aggregation of variables be forbidden?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/donotaggr = FALSE

# maximal number of variables priced in per pricing round
# [type: int, advanced: FALSE, range: [1,2147483647], default: 100]
pricing/maxvars = 100

# maximal number of priced variables at the root node
# [type: int, advanced: FALSE, range: [1,2147483647], default: 2000]
pricing/maxvarsroot = 2000

# pricing is aborted, if fac * pricing/maxvars pricing candidates were found
# [type: real, advanced: FALSE, range: [1,1.79769313486232e+308], default: 2]
pricing/abortfac = 2

# should variables created at the current node be deleted when the node is solved in case they are not present in the LP anymore?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
pricing/delvars = FALSE

# should variables created at the root node be deleted when the root is solved in case they are not present in the LP anymore?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
pricing/delvarsroot = FALSE

# maximal number of propagation rounds per node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 100]
propagating/maxrounds = 100

# maximal number of propagation rounds in the root node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 1000]
propagating/maxroundsroot = 1000

# should propagation be aborted immediately? setting this to FALSE could help conflict analysis to produce more conflict constraints
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
propagating/abortoncutoff = TRUE

# should reoptimization used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/enable = FALSE

# maximal number of saved nodes
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 2147483647]
reoptimization/maxsavednodes = 2147483647

# maximal number of bound changes between two stored nodes on one path
# [type: int, advanced: TRUE, range: [0,2147483647], default: 2147483647]
reoptimization/maxdiffofnodes = 2147483647

# save global constraints to separate infeasible subtrees.
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reoptimization/globalcons/sepainfsubtrees = TRUE

# separate the optimal solution, i.e., for constrained shortest path
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/sepabestsol = FALSE

# use variable history of the previous solve if the objctive function has changed only slightly
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/storevarhistory = FALSE

# re-use pseudo costs if the objective function changed only slightly 
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/usepscost = FALSE

# at which reopttype should the LP be solved? (1: transit, 3: strong branched, 4: w/ added logicor, 5: only leafs).
# [type: int, advanced: TRUE, range: [1,5], default: 1]
reoptimization/solvelp = 1

# maximal number of bound changes at node to skip solving the LP
# [type: int, advanced: TRUE, range: [0,2147483647], default: 1]
reoptimization/solvelpdiff = 1

# number of best solutions which should be saved for the following runs. (-1: save all)
# [type: int, advanced: TRUE, range: [0,2147483647], default: 2147483647]
reoptimization/savesols = 2147483647

# similarity of two sequential objective function to disable solving the root LP.
# [type: real, advanced: TRUE, range: [-1,1], default: 0.8]
reoptimization/objsimrootLP = 0.8

# similarity of two objective functions to re-use stored solutions
# [type: real, advanced: TRUE, range: [-1,1], default: -1]
reoptimization/objsimsol = -1

# minimum similarity for using reoptimization of the search tree.
# [type: real, advanced: TRUE, range: [-1,1], default: -1]
reoptimization/delay = -1

# time limit over all reoptimization rounds?.
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/commontimelimit = FALSE

# replace branched inner nodes by their child nodes, if the number of bound changes is not to large
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reoptimization/shrinkinner = TRUE

# try to fix variables at the root node before reoptimizing by probing like strong branching
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reoptimization/strongbranchinginit = TRUE

# delete stored nodes which were not reoptimized
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reoptimization/reducetofrontier = TRUE

# force a restart if the last n optimal solutions were found by heuristic reoptsols
# [type: int, advanced: TRUE, range: [1,2147483647], default: 3]
reoptimization/forceheurrestart = 3

# save constraint propagations
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/saveconsprop = FALSE

# use constraints to reconstruct the subtree pruned be dual reduction when reactivating the node
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reoptimization/usesplitcons = TRUE

# use 'd'efault, 'r'andom or a variable ordering based on 'i'nference score for interdiction branching used during reoptimization
# [type: char, advanced: TRUE, range: {dir}, default: d]
reoptimization/varorderinterdiction = d

# reoptimize cuts found at the root node
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reoptimization/usecuts = FALSE

# maximal age of a cut to be use for reoptimization
# [type: int, advanced: TRUE, range: [0,2147483647], default: 0]
reoptimization/maxcutage = 0

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying separation (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
separating/maxbounddist = 1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying local separation (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 0]
separating/maxlocalbounddist = 0

# maximal ratio between coefficients in strongcg, cmir, and flowcover cuts
# [type: real, advanced: FALSE, range: [1,1e+98], default: 10000]
separating/maxcoefratio = 10000

# minimal efficacy for a cut to enter the LP
# [type: real, advanced: FALSE, range: [0,1e+98], default: 0.0001]
separating/minefficacy = 0.0001

# minimal efficacy for a cut to enter the LP in the root node
# [type: real, advanced: FALSE, range: [0,1e+98], default: 0.0001]
separating/minefficacyroot = 0.0001

# minimal orthogonality for a cut to enter the LP
# [type: real, advanced: FALSE, range: [0,1], default: 0.9]
separating/minortho = 0.9

# minimal orthogonality for a cut to enter the LP in the root node
# [type: real, advanced: FALSE, range: [0,1], default: 0.9]
separating/minorthoroot = 0.9

# factor to scale objective parallelism of cut in separation score calculation
# [type: real, advanced: TRUE, range: [0,1e+98], default: 0.1]
separating/objparalfac = 0.1

# factor to scale integral support of cut in separation score calculation
# [type: real, advanced: TRUE, range: [0,1e+98], default: 0.1]
separating/intsupportfac = 0.1

# minimum cut activity quotient to convert cuts into constraints during a restart (0.0: all cuts are converted)
# [type: real, advanced: FALSE, range: [0,1], default: 0.8]
separating/minactivityquot = 0.8

# function used for calc. scalar prod. in orthogonality test ('e'uclidean, 'd'iscrete)
# [type: char, advanced: TRUE, range: {ed}, default: e]
separating/orthofunc = e

# row norm to use for efficacy calculation ('e'uclidean, 'm'aximum, 's'um, 'd'iscrete)
# [type: char, advanced: TRUE, range: {emsd}, default: e]
separating/efficacynorm = e

# cut selection during restart ('a'ge, activity 'q'uotient)
# [type: char, advanced: TRUE, range: {aq}, default: a]
separating/cutselrestart = a

# cut selection for sub SCIPs  ('a'ge, activity 'q'uotient)
# [type: char, advanced: TRUE, range: {aq}, default: a]
separating/cutselsubscip = a

# maximal number of runs for which separation is enabled (-1: unlimited)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
separating/maxruns = -1

# maximal number of separation rounds per node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
separating/maxrounds = -1

# maximal number of separation rounds in the root node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
separating/maxroundsroot = -1

# maximal number of separation rounds in the root node of a subsequent run (-1: unlimited)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
separating/maxroundsrootsubrun = -1

# maximal additional number of separation rounds in subsequent price-and-cut loops (-1: no additional restriction)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 1]
separating/maxaddrounds = 1

# maximal number of consecutive separation rounds without objective or integrality improvement in local nodes (-1: no additional restriction)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 1]
separating/maxstallrounds = 1

# maximal number of consecutive separation rounds without objective or integrality improvement in the root node (-1: no additional restriction)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 10]
separating/maxstallroundsroot = 10

# maximal number of consecutive separation rounds that increase the size of the LP relaxation per node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 20]
separating/maxincrounds = 20

# maximal number of cuts separated per separation round (0: disable local separation)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 100]
separating/maxcuts = 100

# maximal number of separated cuts at the root node (0: disable root node separation)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 2000]
separating/maxcutsroot = 2000

# maximum age a cut can reach before it is deleted from the global cut pool, or -1 to keep all cuts
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 80]
separating/cutagelimit = 80

# separation frequency for the global cut pool (-1: disable global cut pool, 0: only separate pool at the root)
# [type: int, advanced: FALSE, range: [-1,65534], default: 10]
separating/poolfreq = 10

# parallel optimisation mode, 0: opportunistic or 1: deterministic.
# [type: int, advanced: FALSE, range: [0,1], default: 1]
parallel/mode = 1

# the minimum number of threads used during parallel solve
# [type: int, advanced: FALSE, range: [0,64], default: 1]
parallel/minnthreads = 1

# the maximum number of threads used during parallel solve
# [type: int, advanced: FALSE, range: [0,64], default: 8]
parallel/maxnthreads = 8

# set different random seeds in each concurrent solver?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
concurrent/changeseeds = TRUE

# use different child selection rules in each concurrent solver?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
concurrent/changechildsel = TRUE

# should the concurrent solvers communicate global variable bound changes?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
concurrent/commvarbnds = TRUE

# should the problem be presolved before it is copied to the concurrent solvers?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
concurrent/presolvebefore = TRUE

# maximum number of solutions that will be shared in a one synchronization
# [type: int, advanced: FALSE, range: [0,2147483647], default: 5131912]
concurrent/initseed = 5131912

# initial frequency of synchronization with other threads
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 10]
concurrent/sync/freqinit = 10

# maximal frequency of synchronization with other threads
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 10]
concurrent/sync/freqmax = 10

# factor by which the frequency of synchronization is changed
# [type: real, advanced: FALSE, range: [1,1.79769313486232e+308], default: 1.5]
concurrent/sync/freqfactor = 1.5

# when adapting the synchronization frequency this value is the targeted relative difference by which the absolute gap decreases per synchronization
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 0.001]
concurrent/sync/targetprogress = 0.001

# maximum number of solutions that will be shared in a single synchronization
# [type: int, advanced: FALSE, range: [0,1000], default: 3]
concurrent/sync/maxnsols = 3

# maximum number of synchronizations before reading is enforced regardless of delay
# [type: int, advanced: TRUE, range: [0,100], default: 7]
concurrent/sync/maxnsyncdelay = 7

# minimum delay before synchronization data is read
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 10]
concurrent/sync/minsyncdelay = 10

# how many of the N best solutions should be considered for synchronization?
# [type: int, advanced: FALSE, range: [0,2147483647], default: 10]
concurrent/sync/nbestsols = 10

# path prefix for parameter setting files of concurrent solvers
# [type: string, advanced: FALSE, default: ""]
concurrent/paramsetprefix = ""

# default clock type (1: CPU user seconds, 2: wall clock time)
# [type: int, advanced: FALSE, range: [1,2], default: 1]
timing/clocktype = 1

# is timing enabled?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
timing/enabled = TRUE

# belongs reading time to solving time?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
timing/reading = FALSE

# should clock checks of solving time be performed less frequently (note: time limit could be exceeded slightly)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
timing/rareclockcheck = FALSE

# should timing for statistic output be performed?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
timing/statistictiming = TRUE

# name of the VBC tool output file, or - if no VBC tool output should be created
# [type: string, advanced: FALSE, default: "-"]
visual/vbcfilename = "-"

# name of the BAK tool output file, or - if no BAK tool output should be created
# [type: string, advanced: FALSE, default: "-"]
visual/bakfilename = "-"

# should the real solving time be used instead of a time step counter in visualization?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
visual/realtime = TRUE

# should the node where solutions are found be visualized?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
visual/dispsols = FALSE

# should be output the external value of the objective?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
visual/objextern = TRUE

# should model constraints be marked as initial?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/initialconss = TRUE

# should model constraints be subject to aging?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/dynamicconss = TRUE

# should columns be added and removed dynamically to the LP?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/dynamiccols = FALSE

# should rows be added and removed dynamically to the LP?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/dynamicrows = FALSE

# should all constraints be written (including the redundant constraints)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
write/allconss = FALSE

# should variables set to zero be printed?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
write/printzeros = FALSE

# when writing a generic problem the index for the first variable should start with?
# [type: int, advanced: FALSE, range: [0,1073741823], default: 0]
write/genericnamesoffset = 0

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/nonlinear/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/nonlinear/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/nonlinear/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/nonlinear/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/nonlinear/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/nonlinear/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/nonlinear/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/nonlinear/presoltiming = 28

# maximal coef range of a cut (maximal coefficient divided by minimal coefficient) in order to be added to LP relaxation
# [type: real, advanced: FALSE, range: [0,1e+20], default: 10000000]
constraints/nonlinear/cutmaxrange = 10000000

# whether to try to make solutions in check function feasible by shifting a linear variable (esp. useful if constraint was actually objective function)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/linfeasshift = TRUE

# whether to assume that nonlinear functions in inequalities (<=) are convex (disables reformulation)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/nonlinear/assumeconvex = FALSE

# limit on number of propagation rounds for a single constraint within one round of SCIP propagation
# [type: int, advanced: FALSE, range: [0,2147483647], default: 1]
constraints/nonlinear/maxproprounds = 1

# whether to reformulate expression graph
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/reformulate = TRUE

# maximal exponent where still expanding non-monomial polynomials in expression simplification
# [type: int, advanced: TRUE, range: [1,2147483647], default: 2]
constraints/nonlinear/maxexpansionexponent = 2

# minimal required fraction of continuous variables in problem to use solution of NLP relaxation in root for separation
# [type: real, advanced: FALSE, range: [0,2], default: 1]
constraints/nonlinear/sepanlpmincont = 1

# are cuts added during enforcement removable from the LP in the same node?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/nonlinear/enfocutsremovable = FALSE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/quadratic/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/quadratic/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/quadratic/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/quadratic/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/quadratic/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/quadratic/presoltiming = 28

# max. length of linear term which when multiplied with a binary variables is replaced by an auxiliary variable and a linear reformulation (0 to turn off)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 2147483647]
constraints/quadratic/replacebinaryprod = 2147483647

# empathy level for using the AND constraint handler: 0 always avoid using AND; 1 use AND sometimes; 2 use AND as often as possible
# [type: int, advanced: FALSE, range: [0,2], default: 0]
constraints/quadratic/empathy4and = 0

# whether to make non-varbound linear constraints added due to replacing products with binary variables initial
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/binreforminitial = FALSE

# whether to consider only binary variables when replacing products with binary variables
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/binreformbinaryonly = TRUE

# limit (as factor on 1/feastol) on coefficients and coef. range in linear constraints created when replacing products with binary variables
# [type: real, advanced: TRUE, range: [0,1e+20], default: 0.0001]
constraints/quadratic/binreformmaxcoef = 0.0001

# maximal coef range of a cut (maximal coefficient divided by minimal coefficient) in order to be added to LP relaxation
# [type: real, advanced: TRUE, range: [0,1e+20], default: 10000000]
constraints/quadratic/cutmaxrange = 10000000

# minimal curvature of constraints to be considered when returning bilinear terms to other plugins
# [type: real, advanced: TRUE, range: [-1e+20,1e+20], default: 0.8]
constraints/quadratic/mincurvcollectbilinterms = 0.8

# whether linearizations of convex quadratic constraints should be added to cutpool in a solution found by some heuristic
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/linearizeheursol = TRUE

# whether multivariate quadratic functions should be checked for convexity/concavity
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/checkcurvature = TRUE

# whether constraint functions should be checked to be factorable
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/checkfactorable = TRUE

# whether quadratic variables contained in a single constraint should be forced to be at their lower or upper bounds ('d'isable, change 't'ype, add 'b'ound disjunction)
# [type: char, advanced: TRUE, range: {bdt}, default: t]
constraints/quadratic/checkquadvarlocks = t

# whether to try to make solutions in check function feasible by shifting a linear variable (esp. useful if constraint was actually objective function)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/linfeasshift = TRUE

# maximum number of created constraints when disaggregating a quadratic constraint (<= 1: off)
# [type: int, advanced: FALSE, range: [1,2147483647], default: 127]
constraints/quadratic/maxdisaggrsize = 127

# strategy how to merge independent blocks to reach maxdisaggrsize limit (keep 'b'iggest blocks and merge others; keep 's'mallest blocks and merge other; merge small blocks into bigger blocks to reach 'm'ean sizes)
# [type: char, advanced: TRUE, range: {bms}, default: m]
constraints/quadratic/disaggrmergemethod = m

# limit on number of propagation rounds for a single constraint within one round of SCIP propagation during solve
# [type: int, advanced: TRUE, range: [0,2147483647], default: 1]
constraints/quadratic/maxproprounds = 1

# limit on number of propagation rounds for a single constraint within one round of SCIP presolve
# [type: int, advanced: TRUE, range: [0,2147483647], default: 10]
constraints/quadratic/maxproproundspresolve = 10

# maximum number of enforcement rounds before declaring the LP relaxation infeasible (-1: no limit); WARNING: changing this parameter might lead to incorrect results!
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/quadratic/enfolplimit = -1

# minimal required fraction of continuous variables in problem to use solution of NLP relaxation in root for separation
# [type: real, advanced: FALSE, range: [0,2], default: 1]
constraints/quadratic/sepanlpmincont = 1

# are cuts added during enforcement removable from the LP in the same node?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/enfocutsremovable = FALSE

# should convex quadratics generated strong cuts via gauge function?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/gaugecuts = TRUE

# how the interior point for gauge cuts should be computed: 'a'ny point per constraint, 'm'ost interior per constraint
# [type: char, advanced: TRUE, range: {am}, default: a]
constraints/quadratic/interiorcomputation = a

# should convex quadratics generated strong cuts via projections?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/projectedcuts = FALSE

# which score to give branching candidates: convexification 'g'ap, constraint 'v'iolation, 'c'entrality of variable value in domain
# [type: char, advanced: TRUE, range: {cgv}, default: g]
constraints/quadratic/branchscoring = g

# should linear inequalities be consindered when computing the branching scores for bilinear terms?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/usebilinineqbranch = FALSE

# minimal required score in order to use linear inequalities for tighter bilinear relaxations
# [type: real, advanced: FALSE, range: [0,1], default: 0.01]
constraints/quadratic/minscorebilinterms = 0.01

# maximum number of separation rounds to use linear inequalities for the bilinear term relaxation in a local node
# [type: int, advanced: TRUE, range: [0,2147483647], default: 3]
constraints/quadratic/bilinineqmaxseparounds = 3

# enable nonlinear upgrading for constraint handler <quadratic>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/upgrade/quadratic = TRUE

# priority of conflict handler <linear>
# [type: int, advanced: TRUE, range: [-2147483648,2147483647], default: -1000000]
conflict/linear/priority = -1000000

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/linear/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/linear/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/linear/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/linear/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/linear/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 20]
constraints/linear/presoltiming = 20

# enable quadratic upgrading for constraint handler <linear>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/upgrade/linear = TRUE

# enable nonlinear upgrading for constraint handler <linear>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/upgrade/linear = TRUE

# multiplier on propagation frequency, how often the bounds are tightened (-1: never, 0: only at root)
# [type: int, advanced: TRUE, range: [-1,65534], default: 1]
constraints/linear/tightenboundsfreq = 1

# maximal number of separation rounds per node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 5]
constraints/linear/maxrounds = 5

# maximal number of separation rounds per node in the root node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
constraints/linear/maxroundsroot = -1

# maximal number of cuts separated per separation round
# [type: int, advanced: FALSE, range: [0,2147483647], default: 50]
constraints/linear/maxsepacuts = 50

# maximal number of cuts separated per separation round in the root node
# [type: int, advanced: FALSE, range: [0,2147483647], default: 200]
constraints/linear/maxsepacutsroot = 200

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/presolusehashing = TRUE

# number for minimal pairwise presolve comparisons
# [type: int, advanced: TRUE, range: [1,2147483647], default: 200000]
constraints/linear/nmincomparisons = 200000

# minimal gain per minimal pairwise presolve comparisons to repeat pairwise comparison round
# [type: real, advanced: TRUE, range: [0,1], default: 1e-06]
constraints/linear/mingainpernmincomparisons = 1e-06

# maximal allowed relative gain in maximum norm for constraint aggregation (0.0: disable constraint aggregation)
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0]
constraints/linear/maxaggrnormscale = 0

# maximum activity delta to run easy propagation on linear constraint (faster, but numerically less stable)
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1000000]
constraints/linear/maxeasyactivitydelta = 1000000

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for separating knapsack cardinality cuts
# [type: real, advanced: TRUE, range: [0,1], default: 0]
constraints/linear/maxcardbounddist = 0

# should all constraints be subject to cardinality cut generation instead of only the ones with non-zero dual value?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/separateall = FALSE

# should presolving search for aggregations in equations
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/aggregatevariables = TRUE

# should presolving try to simplify inequalities
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/simplifyinequalities = TRUE

# should dual presolving steps be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/dualpresolving = TRUE

# should stuffing of singleton continuous variables be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/singletonstuffing = TRUE

# should single variable stuffing be performed, which tries to fulfill constraints using the cheapest variable?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/singlevarstuffing = FALSE

# apply binaries sorting in decr. order of coeff abs value?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/sortvars = TRUE

# should the violation for a constraint with side 0.0 be checked relative to 1.0 (FALSE) or to the maximum absolute value in the activity (TRUE)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/checkrelmaxabs = FALSE

# should presolving try to detect constraints parallel to the objective function defining an upper bound and prevent these constraints from entering the LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/detectcutoffbound = TRUE

# should presolving try to detect constraints parallel to the objective function defining a lower bound and prevent these constraints from entering the LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/detectlowerbound = TRUE

# should presolving try to detect subsets of constraints parallel to the objective function?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/detectpartialobjective = TRUE

# should presolving and propagation try to improve bounds, detect infeasibility, and extract sub-constraints from ranged rows and equations?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/rangedrowpropagation = TRUE

# should presolving and propagation extract sub-constraints from ranged rows and equations?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/rangedrowartcons = TRUE

# maximum depth to apply ranged row propagation
# [type: int, advanced: TRUE, range: [0,2147483647], default: 2147483647]
constraints/linear/rangedrowmaxdepth = 2147483647

# frequency for applying ranged row propagation
# [type: int, advanced: TRUE, range: [1,65534], default: 1]
constraints/linear/rangedrowfreq = 1

# should multi-aggregations only be performed if the constraint can be removed afterwards?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linear/multaggrremove = FALSE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/abspower/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/abspower/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 15]
constraints/abspower/proptiming = 15

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/abspower/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/abspower/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/abspower/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/abspower/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 12]
constraints/abspower/presoltiming = 12

# enable quadratic upgrading for constraint handler <abspower>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/upgrade/abspower = TRUE

# enable nonlinear upgrading for constraint handler <abspower>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/upgrade/abspower = TRUE

# maximal coef range of a cut (maximal coefficient divided by minimal coefficient) in order to be added to LP relaxation
# [type: real, advanced: FALSE, range: [0,1e+20], default: 10000000]
constraints/abspower/cutmaxrange = 10000000

# whether to project the reference point when linearizing an absolute power constraint in a convex region
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/abspower/projectrefpoint = TRUE

# how much to prefer branching on 0.0 when sign of variable is not fixed yet: 0 no preference, 1 prefer if LP solution will be cutoff in both child nodes, 2 prefer always, 3 ensure always
# [type: int, advanced: FALSE, range: [0,3], default: 1]
constraints/abspower/preferzerobranch = 1

# whether to compute branching point such that the convexification error is minimized (after branching on 0.0)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/abspower/branchminconverror = FALSE

# should variable bound constraints be added for derived variable bounds?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/abspower/addvarboundcons = TRUE

# whether to try to make solutions in check function feasible by shifting the linear variable z
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/abspower/linfeasshift = TRUE

# should dual presolve be applied?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/abspower/dualpresolve = TRUE

# whether to separate linearization cuts only in the variable bounds (does not affect enforcement)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/abspower/sepainboundsonly = FALSE

# minimal required fraction of continuous variables in problem to use solution of NLP relaxation in root for separation
# [type: real, advanced: FALSE, range: [0,2], default: 1]
constraints/abspower/sepanlpmincont = 1

# are cuts added during enforcement removable from the LP in the same node?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/abspower/enfocutsremovable = FALSE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/and/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/and/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/and/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/and/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/and/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/and/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/and/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 20]
constraints/and/presoltiming = 20

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/and/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/and/presolusehashing = TRUE

# should the AND-constraint get linearized and removed (in presolving)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/and/linearize = FALSE

# should cuts be separated during LP enforcing?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/and/enforcecuts = TRUE

# should an aggregated linearization be used?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/and/aggrlinearization = FALSE

# should all binary resultant variables be upgraded to implicit binary variables?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/and/upgraderesultant = TRUE

# should dual presolving be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/and/dualpresolving = TRUE

# enable nonlinear upgrading for constraint handler <and>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/nonlinear/upgrade/and = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/bivariate/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/bivariate/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/bivariate/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/bivariate/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/bivariate/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/bivariate/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/bivariate/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/bivariate/presoltiming = 4

# enable quadratic upgrading for constraint handler <bivariate>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/quadratic/upgrade/bivariate = FALSE

# enable nonlinear upgrading for constraint handler <bivariate>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/nonlinear/upgrade/bivariate = FALSE

# maximal coef range of a cut (maximal coefficient divided by minimal coefficient) in order to be added to LP relaxation
# [type: real, advanced: TRUE, range: [0,1e+20], default: 10000000]
constraints/bivariate/cutmaxrange = 10000000

# whether to try to make solutions in check function feasible by shifting a linear variable (esp. useful if constraint was actually objective function)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/bivariate/linfeasshift = TRUE

# limit on number of propagation rounds for a single constraint within one round of SCIP propagation
# [type: int, advanced: FALSE, range: [0,2147483647], default: 1]
constraints/bivariate/maxproprounds = 1

# number of reference points in each direction where to compute linear support for envelope in LP initialization
# [type: int, advanced: FALSE, range: [0,2147483647], default: 3]
constraints/bivariate/ninitlprefpoints = 3

# are cuts added during enforcement removable from the LP in the same node?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/bivariate/enfocutsremovable = FALSE

# maximal percantage of continuous variables within a conflict
# [type: real, advanced: FALSE, range: [0,1], default: 0.4]
conflict/bounddisjunction/continuousfrac = 0.4

# priority of conflict handler <bounddisjunction>
# [type: int, advanced: TRUE, range: [-2147483648,2147483647], default: -3000000]
conflict/bounddisjunction/priority = -3000000

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/bounddisjunction/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/bounddisjunction/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/bounddisjunction/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/bounddisjunction/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/bounddisjunction/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/bounddisjunction/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/bounddisjunction/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/bounddisjunction/presoltiming = 4

# enable quadratic upgrading for constraint handler <bounddisjunction>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/upgrade/bounddisjunction = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 10]
constraints/cardinality/sepafreq = 10

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/cardinality/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/cardinality/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/cardinality/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/cardinality/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cardinality/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cardinality/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/cardinality/presoltiming = 4

# whether to use balanced instead of unbalanced branching
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cardinality/branchbalanced = FALSE

# maximum depth for using balanced branching (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 20]
constraints/cardinality/balanceddepth = 20

# determines that balanced branching is only used if the branching cut off value          w.r.t. the current LP solution is greater than a given value
# [type: real, advanced: TRUE, range: [0.01,1.79769313486232e+308], default: 2]
constraints/cardinality/balancedcutoff = 2

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/conjunction/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/conjunction/propfreq = -1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/conjunction/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/conjunction/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/conjunction/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/conjunction/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/conjunction/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/conjunction/presoltiming = 4

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/countsols/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/countsols/propfreq = -1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/countsols/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/countsols/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 0]
constraints/countsols/maxprerounds = 0

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/countsols/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/countsols/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/countsols/presoltiming = 28

# is the constraint handler active?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/countsols/active = FALSE

# should the sparse solution test be turned on?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/countsols/sparsetest = TRUE

# is it allowed to discard solutions?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/countsols/discardsols = TRUE

# should the solutions be collected?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/countsols/collect = FALSE

# counting stops, if the given number of solutions were found (-1: no limit)
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: -1]
constraints/countsols/sollimit = -1

# display activation status of display column <sols> (0: off, 1: auto, 2:on)
# [type: int, advanced: FALSE, range: [0,2], default: 0]
display/sols/active = 0

# display activation status of display column <feasST> (0: off, 1: auto, 2:on)
# [type: int, advanced: FALSE, range: [0,2], default: 0]
display/feasST/active = 0

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/cumulative/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/cumulative/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/cumulative/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/cumulative/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/cumulative/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/cumulative/presoltiming = 28

# should time-table (core-times) propagator be used to infer bounds?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/ttinfer = TRUE

# should edge-finding be used to detect an overload?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/efcheck = FALSE

# should edge-finding be used to infer bounds?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/efinfer = FALSE

# should edge-finding be executed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/useadjustedjobs = FALSE

# should time-table edge-finding be used to detect an overload?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/ttefcheck = TRUE

# should time-table edge-finding be used to infer bounds?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/ttefinfer = TRUE

# should the binary representation be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/usebinvars = FALSE

# should cuts be added only locally?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/localcuts = FALSE

# should covering cuts be added every node?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/usecovercuts = TRUE

# should the cumulative constraint create cuts as knapsack constraints?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/cutsasconss = TRUE

# shall old sepa algo be applied?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/sepaold = TRUE

# should branching candidates be added to storage?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/fillbranchcands = FALSE

# should dual presolving be applied?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/dualpresolve = TRUE

# should coefficient tightening be applied?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/cumulative/coeftightening = FALSE

# should demands and capacity be normalized?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/normalize = TRUE

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/presolpairwise = TRUE

# extract disjunctive constraints?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/disjunctive = TRUE

# number of branch-and-bound nodes to solve an independent cumulative constraint (-1: no limit)?
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: 10000]
constraints/cumulative/maxnodes = 10000

# search for conflict set via maximal cliques to detect disjunctive constraints
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/detectdisjunctive = TRUE

# search for conflict set via maximal cliques to detect variable bound constraints
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/detectvarbounds = TRUE

# should bound widening be used during the conflict analysis?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/cumulative/usebdwidening = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/disjunction/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/disjunction/propfreq = -1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/disjunction/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/disjunction/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/disjunction/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/disjunction/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/disjunction/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/disjunction/presoltiming = 4

# alawys perform branching if one of the constraints is violated, otherwise only if all integers are fixed
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/disjunction/alwaysbranch = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 10]
constraints/indicator/sepafreq = 10

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/indicator/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/indicator/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/indicator/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/indicator/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/indicator/presoltiming = 4

# enable linear upgrading for constraint handler <indicator>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/indicator = TRUE

# priority of conflict handler <indicatorconflict>
# [type: int, advanced: TRUE, range: [-2147483648,2147483647], default: 200000]
conflict/indicatorconflict/priority = 200000

# Branch on indicator constraints in enforcing?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/branchindicators = FALSE

# Generate logicor constraints instead of cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/genlogicor = FALSE

# Add coupling constraints or rows if big-M is small enough?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/indicator/addcoupling = TRUE

# maximum coefficient for binary variable in coupling constraint
# [type: real, advanced: TRUE, range: [0,1000000000], default: 10000]
constraints/indicator/maxcouplingvalue = 10000

# Add initial variable upper bound constraints, if 'addcoupling' is true?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/addcouplingcons = FALSE

# Should the coupling inequalities be separated dynamically?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/indicator/sepacouplingcuts = TRUE

# Allow to use local bounds in order to separate coupling inequalities?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/sepacouplinglocal = FALSE

# maximum coefficient for binary variable in separated coupling constraint
# [type: real, advanced: TRUE, range: [0,1000000000], default: 10000]
constraints/indicator/sepacouplingvalue = 10000

# Separate cuts based on perspective formulation?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/sepaperspective = FALSE

# Allow to use local bounds in order to separate perspective cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/indicator/sepapersplocal = TRUE

# maximal number of separated non violated IISs, before separation is stopped
# [type: int, advanced: FALSE, range: [0,2147483647], default: 3]
constraints/indicator/maxsepanonviolated = 3

# Update bounds of original variables for separation?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/updatebounds = FALSE

# maximum estimated condition of the solution basis matrix of the alternative LP to be trustworthy (0.0 to disable check)
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0]
constraints/indicator/maxconditionaltlp = 0

# maximal number of cuts separated per separation round
# [type: int, advanced: FALSE, range: [0,2147483647], default: 100]
constraints/indicator/maxsepacuts = 100

# maximal number of cuts separated per separation round in the root node
# [type: int, advanced: FALSE, range: [0,2147483647], default: 2000]
constraints/indicator/maxsepacutsroot = 2000

# Remove indicator constraint if corresponding variable bound constraint has been added?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/removeindicators = FALSE

# Do not generate indicator constraint, but a bilinear constraint instead?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/generatebilinear = FALSE

# Scale slack variable coefficient at construction time?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/scaleslackvar = FALSE

# Try to make solutions feasible by setting indicator variables?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/indicator/trysolutions = TRUE

# In enforcing try to generate cuts (only if sepaalternativelp is true)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/enforcecuts = FALSE

# Should dual reduction steps be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/indicator/dualreductions = TRUE

# Add opposite inequality in nodes in which the binary variable has been fixed to 0?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/addopposite = FALSE

# Try to upgrade bounddisjunction conflicts by replacing slack variables?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/conflictsupgrade = FALSE

# fraction of binary variables that need to be fixed before restart occurs (in forcerestart)
# [type: real, advanced: TRUE, range: [0,1], default: 0.9]
constraints/indicator/restartfrac = 0.9

# Collect other constraints to alternative LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/useotherconss = FALSE

# Use objective cut with current best solution to alternative LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/useobjectivecut = FALSE

# Try to construct a feasible solution from a cover?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/trysolfromcover = FALSE

# Try to upgrade linear constraints to indicator constraints?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/upgradelinear = FALSE

# Separate using the alternative LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/sepaalternativelp = FALSE

# Force restart if absolute gap is 1 or enough binary variables have been fixed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/forcerestart = FALSE

# Decompose problem (do not generate linear constraint if all variables are continuous)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/indicator/nolinconscont = FALSE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/integral/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/integral/propfreq = -1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/integral/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
constraints/integral/eagerfreq = -1

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 0]
constraints/integral/maxprerounds = 0

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/integral/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/integral/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/integral/presoltiming = 28

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/knapsack/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/knapsack/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/knapsack/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/knapsack/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/knapsack/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/knapsack/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/knapsack/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/knapsack/presoltiming = 28

# enable linear upgrading for constraint handler <knapsack>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/knapsack = TRUE

# multiplier on separation frequency, how often knapsack cuts are separated (-1: never, 0: only at root)
# [type: int, advanced: TRUE, range: [-1,65534], default: 1]
constraints/knapsack/sepacardfreq = 1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for separating knapsack cuts
# [type: real, advanced: TRUE, range: [0,1], default: 0]
constraints/knapsack/maxcardbounddist = 0

# lower clique size limit for greedy clique extraction algorithm (relative to largest clique)
# [type: real, advanced: TRUE, range: [0,1], default: 0.5]
constraints/knapsack/cliqueextractfactor = 0.5

# maximal number of separation rounds per node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 5]
constraints/knapsack/maxrounds = 5

# maximal number of separation rounds per node in the root node (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
constraints/knapsack/maxroundsroot = -1

# maximal number of cuts separated per separation round
# [type: int, advanced: FALSE, range: [0,2147483647], default: 50]
constraints/knapsack/maxsepacuts = 50

# maximal number of cuts separated per separation round in the root node
# [type: int, advanced: FALSE, range: [0,2147483647], default: 200]
constraints/knapsack/maxsepacutsroot = 200

# should disaggregation of knapsack constraints be allowed in preprocessing?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/disaggregation = TRUE

# should presolving try to simplify knapsacks
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/simplifyinequalities = TRUE

# should negated clique information be used in solving process
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/negatedclique = TRUE

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/presolusehashing = TRUE

# should dual presolving steps be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/dualpresolving = TRUE

# should GUB information be used for separation?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/knapsack/usegubs = FALSE

# should presolving try to detect constraints parallel to the objective function defining an upper bound and prevent these constraints from entering the LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/detectcutoffbound = TRUE

# should presolving try to detect constraints parallel to the objective function defining a lower bound and prevent these constraints from entering the LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/knapsack/detectlowerbound = TRUE

# should clique partition information be updated when old partition seems outdated?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/knapsack/updatecliquepartitions = FALSE

# factor on the growth of global cliques to decide when to update a previous (negated) clique partition (used only if updatecliquepartitions is set to TRUE)
# [type: real, advanced: TRUE, range: [1,10], default: 1.5]
constraints/knapsack/clqpartupdatefac = 1.5

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/linking/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/linking/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/linking/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/linking/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/linking/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linking/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/linking/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/linking/presoltiming = 8

# this constraint will not propagate or separate, linear and setppc are used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/linking/linearize = FALSE

# priority of conflict handler <logicor>
# [type: int, advanced: TRUE, range: [-2147483648,2147483647], default: 800000]
conflict/logicor/priority = 800000

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/logicor/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/logicor/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/logicor/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/logicor/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/logicor/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/logicor/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/logicor/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/logicor/presoltiming = 28

# enable linear upgrading for constraint handler <logicor>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/logicor = TRUE

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/presolusehashing = TRUE

# should dual presolving steps be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/dualpresolving = TRUE

# should negated clique information be used in presolving
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/negatedclique = TRUE

# should implications/cliques be used in presolving
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/implications = TRUE

# should pairwise constraint comparison try to strengthen constraints by removing superflous non-zeros?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/logicor/strengthen = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/or/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/or/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/or/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/or/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/or/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/or/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/or/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/or/presoltiming = 8

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/orbisack/sepafreq = 5

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/orbisack/propfreq = 5

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/orbisack/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
constraints/orbisack/eagerfreq = -1

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/orbisack/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbisack/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbisack/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
constraints/orbisack/presoltiming = 16

# Separate cover inequalities for orbisacks?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/orbisack/orbisack/coverseparation = TRUE

# Separate orbisack inequalities?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbisack/orbiSeparation = FALSE

# Maximum size of coefficients for orbisack inequalities
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1000000]
constraints/orbisack/coeffbound = 1000000

# Upgrade orbisack constraints to packing/partioning orbisacks?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/orbisack/checkpporbisack = TRUE

# Whether check routine returns always SCIP_FEASIBLE.
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/orbisack/checkalwaysfeas = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/orbitope/sepafreq = 5

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/orbitope/propfreq = 5

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/orbitope/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
constraints/orbitope/eagerfreq = -1

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/orbitope/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbitope/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbitope/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/orbitope/presoltiming = 8

# Strengthen orbitope constraints to packing/partioning orbitopes?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/orbitope/checkpporbitope = TRUE

# Whether we separate inequalities for full orbitopes?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/orbitope/sepafullorbitope = FALSE

# Whether check routine returns always SCIP_FEASIBLE.
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/orbitope/checkalwaysfeas = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/pseudoboolean/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/pseudoboolean/propfreq = -1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/pseudoboolean/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/pseudoboolean/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/pseudoboolean/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/pseudoboolean/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/pseudoboolean/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/pseudoboolean/presoltiming = 8

# decompose all normal pseudo boolean constraint into a "linear" constraint and "and" constraints
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/pseudoboolean/decomposenormal = FALSE

# decompose all indicator pseudo boolean constraint into a "linear" constraint and "and" constraints
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/pseudoboolean/decomposeindicator = TRUE

# should the nonlinear constraints be separated during LP processing?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/pseudoboolean/nlcseparate = TRUE

# should the nonlinear constraints be propagated during node processing?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/pseudoboolean/nlcpropagate = TRUE

# should the nonlinear constraints be removable?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/pseudoboolean/nlcremovable = TRUE

# priority of conflict handler <setppc>
# [type: int, advanced: TRUE, range: [-2147483648,2147483647], default: 700000]
conflict/setppc/priority = 700000

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/setppc/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/setppc/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/setppc/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/setppc/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/setppc/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/setppc/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/setppc/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/setppc/presoltiming = 28

# enable linear upgrading for constraint handler <setppc>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/setppc = TRUE

# enable quadratic upgrading for constraint handler <setppc>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/upgrade/setppc = TRUE

# number of children created in pseudo branching (0: disable pseudo branching)
# [type: int, advanced: TRUE, range: [0,2147483647], default: 2]
constraints/setppc/npseudobranches = 2

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/setppc/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/setppc/presolusehashing = TRUE

# should dual presolving steps be performed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/setppc/dualpresolving = TRUE

#  should we try to lift variables into other clique constraints, fix variables, aggregate them, and also shrink the amount of variables in clique constraints
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/setppc/cliquelifting = FALSE

# should we try to generate extra cliques out of all binary variables to maybe fasten redundant constraint detection
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/setppc/addvariablesascliques = FALSE

# should we try to shrink the number of variables in a clique constraints, by replacing more than one variable by only one
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/setppc/cliqueshrinking = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/soc/sepafreq = 1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/soc/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/soc/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/soc/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/soc/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/soc/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/soc/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/soc/presoltiming = 28

# enable quadratic upgrading for constraint handler <soc>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/quadratic/upgrade/soc = TRUE

# whether the reference point of a cut should be projected onto the feasible set of the SOC constraint
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/soc/projectpoint = FALSE

# number of auxiliary variables to use when creating a linear outer approx. of a SOC3 constraint; 0 to turn off
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
constraints/soc/nauxvars = 0

# whether the Glineur Outer Approximation should be used instead of Ben-Tal Nemirovski
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/soc/glineur = TRUE

# whether to sparsify cuts
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/soc/sparsify = FALSE

# maximal loss in cut efficacy by sparsification
# [type: real, advanced: TRUE, range: [0,1], default: 0.2]
constraints/soc/sparsifymaxloss = 0.2

# growth rate of maximal allowed nonzeros in cuts in sparsification
# [type: real, advanced: TRUE, range: [1.000001,1e+20], default: 1.3]
constraints/soc/sparsifynzgrowth = 1.3

# whether to try to make solutions feasible in check by shifting the variable on the right hand side
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/soc/linfeasshift = TRUE

# which formulation to use when adding a SOC constraint to the NLP (a: automatic, q: nonconvex quadratic form, s: convex sqrt form, e: convex exponential-sqrt form, d: convex division form)
# [type: char, advanced: FALSE, range: {aqsed}, default: a]
constraints/soc/nlpform = a

# minimal required fraction of continuous variables in problem to use solution of NLP relaxation in root for separation
# [type: real, advanced: FALSE, range: [0,2], default: 1]
constraints/soc/sepanlpmincont = 1

# are cuts added during enforcement removable from the LP in the same node?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/soc/enfocutsremovable = FALSE

# try to upgrade more general quadratics to soc?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/soc/generalsocupgrade = TRUE

# try to completely disaggregate soc?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/soc/disaggregate = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 10]
constraints/SOS1/sepafreq = 10

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/SOS1/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/SOS1/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/SOS1/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/SOS1/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/SOS1/presoltiming = 8

# do not create an adjacency matrix if number of SOS1 variables is larger than predefined value (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 10000]
constraints/SOS1/maxsosadjacency = 10000

# maximal number of extensions that will be computed for each SOS1 constraint  (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 1]
constraints/SOS1/maxextensions = 1

# maximal number of bound tightening rounds per presolving round (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 5]
constraints/SOS1/maxtightenbds = 5

# if TRUE then perform implication graph analysis (might add additional SOS1 constraints)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/perfimplanalysis = FALSE

# number of recursive calls of implication graph analysis (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/SOS1/depthimplanalysis = -1

# whether to use conflict graph propagation
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/conflictprop = TRUE

# whether to use implication graph propagation
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/implprop = TRUE

# whether to use SOS1 constraint propagation
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/sosconsprop = FALSE

# which branching rule should be applied ? ('n': neighborhood, 'b': bipartite, 's': SOS1/clique) (note: in some cases an automatic switching to SOS1 branching is possible)
# [type: char, advanced: TRUE, range: {nbs}, default: n]
constraints/SOS1/branchingrule = n

# if TRUE then automatically switch to SOS1 branching if the SOS1 constraints do not overlap
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/autosos1branch = TRUE

# if neighborhood branching is used, then fix the branching variable (if positive in sign) to the value of the feasibility tolerance
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/fixnonzero = FALSE

# if TRUE then add complementarity constraints to the branching nodes (can be used in combination with neighborhood or bipartite branching)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/addcomps = FALSE

# maximal number of complementarity constraints added per branching node (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/SOS1/maxaddcomps = -1

# minimal feasibility value for complementarity constraints in order to be added to the branching node
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: -0.6]
constraints/SOS1/addcompsfeas = -0.6

# minimal feasibility value for bound inequalities in order to be added to the branching node
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1]
constraints/SOS1/addbdsfeas = 1

# should added complementarity constraints be extended to SOS1 constraints to get tighter bound inequalities
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/addextendedbds = TRUE

# Use SOS1 branching in enforcing (otherwise leave decision to branching rules)? This value can only be set to false if all SOS1 variables are binary
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/branchsos = TRUE

# Branch on SOS constraint with most number of nonzeros?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/branchnonzeros = FALSE

# Branch on SOS cons. with highest nonzero-variable weight for branching (needs branchnonzeros = false)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/branchweight = FALSE

# only add complementarity constraints to branching nodes for predefined depth (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 30]
constraints/SOS1/addcompsdepth = 30

# maximal number of strong branching rounds to perform for each node (-1: auto); only available for neighborhood and bipartite branching
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 0]
constraints/SOS1/nstrongrounds = 0

# maximal number LP iterations to perform for each strong branching round (-2: auto, -1: no limit)
# [type: int, advanced: TRUE, range: [-2,2147483647], default: 10000]
constraints/SOS1/nstrongiter = 10000

# if TRUE separate bound inequalities from initial SOS1 constraints
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS1/boundcutsfromsos1 = FALSE

# if TRUE separate bound inequalities from the conflict graph
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/boundcutsfromgraph = TRUE

# if TRUE then automatically switch to separating initial SOS1 constraints if the SOS1 constraints do not overlap
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/autocutsfromsos1 = TRUE

# frequency for separating bound cuts; zero means to separate only in the root node
# [type: int, advanced: TRUE, range: [-1,65534], default: 10]
constraints/SOS1/boundcutsfreq = 10

# node depth of separating bound cuts (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 40]
constraints/SOS1/boundcutsdepth = 40

# maximal number of bound cuts separated per branching node
# [type: int, advanced: TRUE, range: [0,2147483647], default: 50]
constraints/SOS1/maxboundcuts = 50

# maximal number of bound cuts separated per iteration in the root node
# [type: int, advanced: TRUE, range: [0,2147483647], default: 150]
constraints/SOS1/maxboundcutsroot = 150

# if TRUE then bound cuts are strengthened in case bound variables are available
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/SOS1/strthenboundcuts = TRUE

# frequency for separating implied bound cuts; zero means to separate only in the root node
# [type: int, advanced: TRUE, range: [-1,65534], default: 0]
constraints/SOS1/implcutsfreq = 0

# node depth of separating implied bound cuts (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 40]
constraints/SOS1/implcutsdepth = 40

# maximal number of implied bound cuts separated per branching node
# [type: int, advanced: TRUE, range: [0,2147483647], default: 50]
constraints/SOS1/maximplcuts = 50

# maximal number of implied bound cuts separated per iteration in the root node
# [type: int, advanced: TRUE, range: [0,2147483647], default: 150]
constraints/SOS1/maximplcutsroot = 150

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/SOS2/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/SOS2/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/SOS2/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/SOS2/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/SOS2/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS2/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/SOS2/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
constraints/SOS2/presoltiming = 4

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/superindicator/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/superindicator/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/superindicator/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/superindicator/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/superindicator/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/superindicator/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/superindicator/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
constraints/superindicator/presoltiming = 8

# should type of slack constraint be checked when creating superindicator constraint?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/superindicator/checkslacktype = TRUE

# maximum big-M coefficient of binary variable in upgrade to a linear constraint (relative to smallest coefficient)
# [type: real, advanced: TRUE, range: [0,1e+15], default: 10000]
constraints/superindicator/maxupgdcoeflinear = 10000

# priority for upgrading to an indicator constraint (-1: never)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 1]
constraints/superindicator/upgdprioindicator = 1

# priority for upgrading to an indicator constraint (-1: never)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 2]
constraints/superindicator/upgdpriolinear = 2

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/symresack/sepafreq = 5

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 5]
constraints/symresack/propfreq = 5

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/symresack/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
constraints/symresack/eagerfreq = -1

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/symresack/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/symresack/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/symresack/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
constraints/symresack/presoltiming = 16

# Upgrade symresack constraints to packing/partioning symresacks?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/symresack/ppsymresack = FALSE

# Whether check routine returns always SCIP_FEASIBLE.
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/symresack/checkalwaysfeas = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/varbound/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/varbound/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/varbound/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/varbound/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/varbound/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/varbound/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/varbound/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 12]
constraints/varbound/presoltiming = 12

# enable linear upgrading for constraint handler <varbound>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/varbound = TRUE

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/varbound/presolpairwise = TRUE

# maximum coefficient in varbound constraint to be added as a row into LP
# [type: real, advanced: TRUE, range: [0,1e+20], default: 1000000000]
constraints/varbound/maxlpcoef = 1000000000

# should bound widening be used in conflict analysis?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/varbound/usebdwidening = TRUE

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 0]
constraints/xor/sepafreq = 0

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/xor/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/xor/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: 100]
constraints/xor/eagerfreq = 100

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/xor/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/xor/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/xor/delayprop = FALSE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 28]
constraints/xor/presoltiming = 28

# enable linear upgrading for constraint handler <xor>
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
constraints/linear/upgrade/xor = TRUE

# should pairwise constraint comparison be performed in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/xor/presolpairwise = TRUE

# should hash table be used for detecting redundant constraints in advance?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/xor/presolusehashing = TRUE

# should the extended formulation be added in presolving?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/xor/addextendedform = FALSE

# should the extended flow formulation be added (nonsymmetric formulation otherwise)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/xor/addflowextended = FALSE

# should parity inequalities be separated?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/xor/separateparity = FALSE

# frequency for applying the Gauss propagator
# [type: int, advanced: TRUE, range: [-1,65534], default: 5]
constraints/xor/gausspropfreq = 5

# frequency for separating cuts (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
constraints/components/sepafreq = -1

# frequency for propagating domains (-1: never, 0: only in root node)
# [type: int, advanced: FALSE, range: [-1,65534], default: 1]
constraints/components/propfreq = 1

# timing when constraint propagation should be called (1:BEFORELP, 2:DURINGLPLOOP, 4:AFTERLPLOOP, 15:ALWAYS)
# [type: int, advanced: TRUE, range: [1,15], default: 1]
constraints/components/proptiming = 1

# frequency for using all instead of only the useful constraints in separation, propagation and enforcement (-1: never, 0: only in first evaluation)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
constraints/components/eagerfreq = -1

# maximal number of presolving rounds the constraint handler participates in (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
constraints/components/maxprerounds = -1

# should separation method be delayed, if other separators found cuts?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
constraints/components/delaysepa = FALSE

# should propagation method be delayed, if other propagators found reductions?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
constraints/components/delayprop = TRUE

# timing mask of the constraint handler's presolving method (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 32]
constraints/components/presoltiming = 32

# maximum depth of a node to run components detection (-1: disable component detection during solving)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
constraints/components/maxdepth = -1

# maximum number of integer (or binary) variables to solve a subproblem during presolving (-1: unlimited)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 500]
constraints/components/maxintvars = 500

# minimum absolute size (in terms of variables) to solve a component individually during branch-and-bound
# [type: int, advanced: TRUE, range: [0,2147483647], default: 50]
constraints/components/minsize = 50

# minimum relative size (in terms of variables) to solve a component individually during branch-and-bound
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
constraints/components/minrelsize = 0.1

# maximum number of nodes to be solved in subproblems during presolving
# [type: longint, advanced: FALSE, range: [-1,9223372036854775807], default: 10000]
constraints/components/nodelimit = 10000

# the weight of an integer variable compared to binary variables
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 1]
constraints/components/intfactor = 1

# factor to increase the feasibility tolerance of the main SCIP in all sub-SCIPs, default value 1.0
# [type: real, advanced: TRUE, range: [0,1000000], default: 1]
constraints/components/feastolfactor = 1

# only use improving bounds
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/bndreader/improveonly = FALSE

# should fixed and aggregated variables be printed (if not, re-parsing might fail)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/cipreader/writefixedvars = TRUE

# should an artificial objective, depending on the number of clauses a variable appears in, be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/cnfreader/useobj = FALSE

# have integer variables no upper bound by default (depending on GAMS version)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/gmsreader/freeints = FALSE

# shall characters '#', '*', '+', '/', and '-' in variable and constraint names be replaced by '_'?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/gmsreader/replaceforbiddenchars = FALSE

# default M value for big-M reformulation of indicator constraints in case no bound on slack variable is given
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 1000000]
reading/gmsreader/bigmdefault = 1000000

# which reformulation to use for indicator constraints: 'b'ig-M, 's'os1
# [type: char, advanced: FALSE, range: {bs}, default: s]
reading/gmsreader/indicatorreform = s

# is it allowed to use the gams function signpower(x,a)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/gmsreader/signpower = FALSE

# should possible "and" constraint be linearized when writing the lp file?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reading/lpreader/linearize-and-constraints = TRUE

# should an aggregated linearization for and constraints be used?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reading/lpreader/aggrlinearization-ands = TRUE

# should possible "and" constraint be linearized when writing the mps file?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reading/mpsreader/linearize-and-constraints = TRUE

# should an aggregated linearization for and constraints be used?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
reading/mpsreader/aggrlinearization-ands = TRUE

# should model constraints be subject to aging?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
reading/opbreader/dynamicconss = FALSE

# use '*' between coefficients and variables by writing to problem?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
reading/opbreader/multisymbol = FALSE

# should the coloring values be relativ or absolute
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/ppmreader/rgbrelativ = TRUE

# should the output format be binary(P6) (otherwise plain(P3) format)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/ppmreader/rgbascii = TRUE

# splitting coefficients in this number of intervals
# [type: int, advanced: FALSE, range: [3,16], default: 3]
reading/ppmreader/coefficientlimit = 3

# maximal color value
# [type: int, advanced: FALSE, range: [0,255], default: 160]
reading/ppmreader/rgblimit = 160

# should the output format be binary(P4) (otherwise plain(P1) format)
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
reading/pbmreader/binary = TRUE

# maximum number of rows in the scaled picture (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 1000]
reading/pbmreader/maxrows = 1000

# maximum number of columns in the scaled picture (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 1000]
reading/pbmreader/maxcols = 1000

# priority of presolver <boundshift>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 7900000]
presolving/boundshift/priority = 7900000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/boundshift/maxrounds = 0

# timing mask of presolver <boundshift> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
presolving/boundshift/timing = 4

# absolute value of maximum shift
# [type: longint, advanced: TRUE, range: [0,9223372036854775807], default: 9223372036854775807]
presolving/boundshift/maxshift = 9223372036854775807

# is flipping allowed (multiplying with -1)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/boundshift/flipping = TRUE

# shift only integer ranges?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/boundshift/integer = TRUE

# priority of presolver <convertinttobin>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 6000000]
presolving/convertinttobin/priority = 6000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/convertinttobin/maxrounds = 0

# timing mask of presolver <convertinttobin> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
presolving/convertinttobin/timing = 4

# absolute value of maximum domain size for converting an integer variable to binaries variables
# [type: longint, advanced: TRUE, range: [0,9223372036854775807], default: 9223372036854775807]
presolving/convertinttobin/maxdomainsize = 9223372036854775807

# should only integer variables with a domain size of 2^p - 1 be converted(, there we don't need an knapsack-constraint for restricting the sum of the binaries)
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/convertinttobin/onlypoweroftwo = FALSE

# should only integer variables with uplocks equals downlocks be converted
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/convertinttobin/samelocksinbothdirections = FALSE

# priority of presolver <domcol>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -1000]
presolving/domcol/priority = -1000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/domcol/maxrounds = -1

# timing mask of presolver <domcol> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/domcol/timing = 16

# minimal number of pair comparisons
# [type: int, advanced: FALSE, range: [100,1048576], default: 1024]
presolving/domcol/numminpairs = 1024

# maximal number of pair comparisons
# [type: int, advanced: FALSE, range: [1024,1000000000], default: 1048576]
presolving/domcol/nummaxpairs = 1048576

# should predictive bound strengthening be applied?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
presolving/domcol/predbndstr = FALSE

# should reductions for continuous variables be performed?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
presolving/domcol/continuousred = TRUE

# priority of presolver <implfree>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -1000]
presolving/implfree/priority = -1000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/implfree/maxrounds = 0

# timing mask of presolver <implfree> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/implfree/timing = 16

# priority of presolver <dualagg>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -12000]
presolving/dualagg/priority = -12000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/dualagg/maxrounds = 0

# timing mask of presolver <dualagg> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/dualagg/timing = 16

# priority of presolver <dualcomp>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -50]
presolving/dualcomp/priority = -50

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/dualcomp/maxrounds = -1

# timing mask of presolver <dualcomp> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/dualcomp/timing = 16

# should only discrete variables be compensated?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
presolving/dualcomp/componlydisvars = FALSE

# priority of presolver <dualinfer>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -2000]
presolving/dualinfer/priority = -2000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/dualinfer/maxrounds = 0

# timing mask of presolver <dualinfer> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/dualinfer/timing = 16

# priority of presolver <gateextraction>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 1000000]
presolving/gateextraction/priority = 1000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/gateextraction/maxrounds = -1

# timing mask of presolver <gateextraction> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/gateextraction/timing = 16

# should we only try to extract set-partitioning constraints and no and-constraints
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/gateextraction/onlysetpart = FALSE

# should we try to extract set-partitioning constraint out of one logicor and one corresponding set-packing constraint
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/gateextraction/searchequations = TRUE

# order logicor contraints to extract big-gates before smaller ones (-1), do not order them (0) or order them to extract smaller gates at first (1)
# [type: int, advanced: TRUE, range: [-1,1], default: 1]
presolving/gateextraction/sorting = 1

# priority of presolver <implics>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -10000]
presolving/implics/priority = -10000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/implics/maxrounds = -1

# timing mask of presolver <implics> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
presolving/implics/timing = 8

# priority of presolver <inttobinary>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 7000000]
presolving/inttobinary/priority = 7000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/inttobinary/maxrounds = -1

# timing mask of presolver <inttobinary> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
presolving/inttobinary/timing = 4

# priority of presolver <qpkktref>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -1]
presolving/qpkktref/priority = -1

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/qpkktref/maxrounds = -1

# timing mask of presolver <qpkktref> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 8]
presolving/qpkktref/timing = 8

# if TRUE then allow binary variables for KKT update
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/qpkktref/addkktbinary = FALSE

# if TRUE then only apply the update to QPs with bounded variables; if the variables are not bounded then a          finite optimal solution might not exist and the KKT conditions would then be invalid
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/qpkktref/updatequadbounded = TRUE

# if TRUE then apply quadratic constraint update even if the quadratic constraint matrix is known to be indefinite
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/qpkktref/updatequadindef = FALSE

# priority of presolver <redvub>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -9000000]
presolving/redvub/priority = -9000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/redvub/maxrounds = 0

# timing mask of presolver <redvub> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/redvub/timing = 16

# priority of presolver <trivial>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 9000000]
presolving/trivial/priority = 9000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/trivial/maxrounds = -1

# timing mask of presolver <trivial> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 4]
presolving/trivial/timing = 4

# priority of presolver <tworowbnd>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -500000]
presolving/tworowbnd/priority = -500000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/tworowbnd/maxrounds = 0

# timing mask of presolver <tworowbnd> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/tworowbnd/timing = 16

# priority of presolver <sparsify>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -24000]
presolving/sparsify/priority = -24000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/sparsify/maxrounds = -1

# timing mask of presolver <sparsify> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/sparsify/timing = 16

# should sparsify presolver be copied to sub-SCIPs?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/sparsify/enablecopy = TRUE

# should we cancel nonzeros in constraints of the linear constraint handler?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/sparsify/cancellinear = TRUE

# should we forbid cancellations that destroy integer coefficients?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/sparsify/preserveintcoefs = TRUE

# maximal fillin for continuous variables (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/sparsify/maxcontfillin = 0

# maximal fillin for binary variables (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/sparsify/maxbinfillin = 0

# maximal fillin for integer variables including binaries (-1: unlimited)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/sparsify/maxintfillin = 0

# maximal support of one equality to be used for cancelling (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
presolving/sparsify/maxnonzeros = -1

# maximal number of considered non-zeros within one row (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 70]
presolving/sparsify/maxconsiderednonzeros = 70

# order in which to process inequalities ('n'o sorting, 'i'ncreasing nonzeros, 'd'ecreasing nonzeros)
# [type: char, advanced: TRUE, range: {nid}, default: d]
presolving/sparsify/rowsort = d

# limit on the number of useless vs. useful hashtable retrieves as a multiple of the number of constraints
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 100]
presolving/sparsify/maxretrievefac = 100

# number of calls to wait until next execution as a multiple of the number of useless calls
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 2]
presolving/sparsify/waitingfac = 2

# priority of presolver <stuffing>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -100]
presolving/stuffing/priority = -100

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: 0]
presolving/stuffing/maxrounds = 0

# timing mask of presolver <stuffing> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/stuffing/timing = 16

# priority of presolver <symmetry>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 0]
presolving/symmetry/priority = 0

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/symmetry/maxrounds = -1

# timing mask of presolver <symmetry> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/symmetry/timing = 16

# Should the symmetry be computed after presolving (otherwise before presol)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/symmetry/computepresolved = TRUE

# limit on the number of generators that should be produced within symmetry detection (0 = no limit)
# [type: int, advanced: TRUE, range: [0,2147483647], default: 1500]
presolving/symmetry/maxgenerators = 1500

# Should all symmetries be checked after computation?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/symmetry/checksymmetries = FALSE

# priority of presolver <symbreak>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -10000000]
presolving/symbreak/priority = -10000000

# maximal number of presolving rounds the presolver participates in (-1: no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
presolving/symbreak/maxrounds = -1

# timing mask of presolver <symbreak> (4:FAST, 8:MEDIUM, 16:EXHAUSTIVE, 32:FINAL)
# [type: int, advanced: TRUE, range: [4,60], default: 16]
presolving/symbreak/timing = 16

# Should the symmetry breaking constraints be added to the LP?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/symbreak/conssaddlp = TRUE

# Add inequalities for symresacks for each generator?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/symbreak/addsymresacks = TRUE

# Should the orbits of the symmetry group be computed?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
presolving/symbreak/computeorbits = FALSE

# Should we check whether the components of the symmetry group can be handled by orbitopes?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
presolving/symbreak/detectorbitopes = TRUE

# priority of node selection rule <bfs> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 100000]
nodeselection/bfs/stdpriority = 100000

# priority of node selection rule <bfs> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 0]
nodeselection/bfs/memsavepriority = 0

# minimal plunging depth, before new best node may be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/bfs/minplungedepth = -1

# maximal plunging depth, before new best node is forced to be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/bfs/maxplungedepth = -1

# maximal quotient (curlowerbound - lowerbound)/(cutoffbound - lowerbound) where plunging is performed
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.25]
nodeselection/bfs/maxplungequot = 0.25

# priority of node selection rule <breadthfirst> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: -10000]
nodeselection/breadthfirst/stdpriority = -10000

# priority of node selection rule <breadthfirst> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -1000000]
nodeselection/breadthfirst/memsavepriority = -1000000

# priority of node selection rule <dfs> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 0]
nodeselection/dfs/stdpriority = 0

# priority of node selection rule <dfs> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 100000]
nodeselection/dfs/memsavepriority = 100000

# priority of node selection rule <estimate> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 200000]
nodeselection/estimate/stdpriority = 200000

# priority of node selection rule <estimate> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 100]
nodeselection/estimate/memsavepriority = 100

# minimal plunging depth, before new best node may be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/estimate/minplungedepth = -1

# maximal plunging depth, before new best node is forced to be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/estimate/maxplungedepth = -1

# maximal quotient (estimate - lowerbound)/(cutoffbound - lowerbound) where plunging is performed
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.25]
nodeselection/estimate/maxplungequot = 0.25

# frequency at which the best node instead of the best estimate is selected (0: never)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 10]
nodeselection/estimate/bestnodefreq = 10

# depth until breadth-first search is applied
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
nodeselection/estimate/breadthfirstdepth = -1

# number of nodes before doing plunging the first time
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
nodeselection/estimate/plungeoffset = 0

# priority of node selection rule <hybridestim> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 50000]
nodeselection/hybridestim/stdpriority = 50000

# priority of node selection rule <hybridestim> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 50]
nodeselection/hybridestim/memsavepriority = 50

# minimal plunging depth, before new best node may be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/hybridestim/minplungedepth = -1

# maximal plunging depth, before new best node is forced to be selected (-1 for dynamic setting)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: -1]
nodeselection/hybridestim/maxplungedepth = -1

# maximal quotient (estimate - lowerbound)/(cutoffbound - lowerbound) where plunging is performed
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.25]
nodeselection/hybridestim/maxplungequot = 0.25

# frequency at which the best node instead of the hybrid best estimate / best bound is selected (0: never)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 1000]
nodeselection/hybridestim/bestnodefreq = 1000

# weight of estimate value in node selection score (0: pure best bound search, 1: pure best estimate search)
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
nodeselection/hybridestim/estimweight = 0.1

# priority of node selection rule <restartdfs> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 10000]
nodeselection/restartdfs/stdpriority = 10000

# priority of node selection rule <restartdfs> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 50000]
nodeselection/restartdfs/memsavepriority = 50000

# frequency for selecting the best node instead of the deepest one
# [type: int, advanced: FALSE, range: [0,2147483647], default: 100]
nodeselection/restartdfs/selectbestfreq = 100

# count only leaf nodes (otherwise all nodes)?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
nodeselection/restartdfs/countonlyleaves = TRUE

# priority of node selection rule <uct> in standard mode
# [type: int, advanced: FALSE, range: [-536870912,1073741823], default: 10]
nodeselection/uct/stdpriority = 10

# priority of node selection rule <uct> in memory saving mode
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 0]
nodeselection/uct/memsavepriority = 0

# maximum number of nodes before switching to default rule
# [type: int, advanced: TRUE, range: [0,1000000], default: 31]
nodeselection/uct/nodelimit = 31

# weight for visit quotient of node selection rule
# [type: real, advanced: TRUE, range: [0,1], default: 0.1]
nodeselection/uct/weight = 0.1

# should the estimate (TRUE) or lower bound of a node be used for UCT score?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
nodeselection/uct/useestimate = FALSE

# priority of branching rule <allfullstrong>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: -1000]
branching/allfullstrong/priority = -1000

# maximal depth level, up to which branching rule <allfullstrong> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/allfullstrong/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/allfullstrong/maxbounddist = 1

# priority of branching rule <cloud>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 0]
branching/cloud/priority = 0

# maximal depth level, up to which branching rule <cloud> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/cloud/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/cloud/maxbounddist = 1

# should a cloud of points be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
branching/cloud/usecloud = TRUE

# should only F2 be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
branching/cloud/onlyF2 = FALSE

# should the union of candidates be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
branching/cloud/useunion = FALSE

# maximum number of points for the cloud (-1 means no limit)
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
branching/cloud/maxpoints = -1

# minimum success rate for the cloud
# [type: real, advanced: FALSE, range: [0,1], default: 0]
branching/cloud/minsuccessrate = 0

# minimum success rate for the union
# [type: real, advanced: FALSE, range: [0,1], default: 0]
branching/cloud/minsuccessunion = 0

# maximum depth for the union
# [type: int, advanced: FALSE, range: [0,65000], default: 65000]
branching/cloud/maxdepthunion = 65000

# priority of branching rule <distribution>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 0]
branching/distribution/priority = 0

# maximal depth level, up to which branching rule <distribution> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/distribution/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/distribution/maxbounddist = 1

# the score;largest 'd'ifference, 'l'owest cumulative probability,'h'ighest c.p., 'v'otes lowest c.p., votes highest c.p.('w') 
# [type: char, advanced: TRUE, range: {dhlvw}, default: v]
branching/distribution/scoreparam = v

# should only rows which are active at the current node be considered?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/distribution/onlyactiverows = FALSE

# should the branching score weigh up- and down-scores of a variable
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/distribution/weightedscore = FALSE

# priority of branching rule <fullstrong>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 0]
branching/fullstrong/priority = 0

# maximal depth level, up to which branching rule <fullstrong> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/fullstrong/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/fullstrong/maxbounddist = 1

# number of intermediate LPs solved to trigger reevaluation of strong branching value for a variable that was already evaluated at the current node
# [type: longint, advanced: TRUE, range: [0,9223372036854775807], default: 10]
branching/fullstrong/reevalage = 10

# maximum number of propagation rounds to be performed during strong branching before solving the LP (-1: no limit, -2: parameter settings)
# [type: int, advanced: TRUE, range: [-2,2147483647], default: -2]
branching/fullstrong/maxproprounds = -2

# should valid bounds be identified in a probing-like fashion during strong branching (only with propagation)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/fullstrong/probingbounds = TRUE

# should strong branching be applied even if there is just a single candidate?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/fullstrong/forcestrongbranch = FALSE

# priority of branching rule <inference>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 1000]
branching/inference/priority = 1000

# maximal depth level, up to which branching rule <inference> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/inference/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/inference/maxbounddist = 1

# weight in score calculations for conflict score
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1000]
branching/inference/conflictweight = 1000

# weight in score calculations for inference score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1]
branching/inference/inferenceweight = 1

# weight in score calculations for cutoff score
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1]
branching/inference/cutoffweight = 1

# should branching on LP solution be restricted to the fractional variables?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/inference/fractionals = TRUE

# should a weighted sum of inference, conflict and cutoff weights be used?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
branching/inference/useweightedsum = TRUE

# weight in score calculations for conflict score
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.001]
branching/inference/reliablescore = 0.001

# priority of branching rule <leastinf>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 50]
branching/leastinf/priority = 50

# maximal depth level, up to which branching rule <leastinf> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/leastinf/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/leastinf/maxbounddist = 1

# priority of branching rule <mostinf>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 100]
branching/mostinf/priority = 100

# maximal depth level, up to which branching rule <mostinf> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/mostinf/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/mostinf/maxbounddist = 1

# priority of branching rule <multaggr>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 0]
branching/multaggr/priority = 0

# maximal depth level, up to which branching rule <multaggr> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/multaggr/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/multaggr/maxbounddist = 1

# number of intermediate LPs solved to trigger reevaluation of strong branching value for a variable that was already evaluated at the current node
# [type: longint, advanced: TRUE, range: [0,9223372036854775807], default: 0]
branching/multaggr/reevalage = 0

# maximum number of propagation rounds to be performed during multaggr branching before solving the LP (-1: no limit, -2: parameter settings)
# [type: int, advanced: TRUE, range: [-2,2147483647], default: 0]
branching/multaggr/maxproprounds = 0

# should valid bounds be identified in a probing-like fashion during multaggr branching (only with propagation)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/multaggr/probingbounds = TRUE

# priority of branching rule <nodereopt>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: -9000000]
branching/nodereopt/priority = -9000000

# maximal depth level, up to which branching rule <nodereopt> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/nodereopt/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/nodereopt/maxbounddist = 1

# priority of branching rule <pscost>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 2000]
branching/pscost/priority = 2000

# maximal depth level, up to which branching rule <pscost> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/pscost/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/pscost/maxbounddist = 1

# strategy for utilizing pseudo-costs of external branching candidates (multiply as in pseudo costs 'u'pdate rule, or by 'd'omain reduction, or by domain reduction of 's'ibling, or by 'v'ariable score)
# [type: char, advanced: FALSE, range: {cdsu}, default: u]
branching/pscost/strategy = u

# weight for minimum of scores of a branching candidate when building weighted sum of min/max/sum of scores
# [type: real, advanced: TRUE, range: [-1e+20,1e+20], default: 0.8]
branching/pscost/minscoreweight = 0.8

# weight for maximum of scores of a branching candidate when building weighted sum of min/max/sum of scores
# [type: real, advanced: TRUE, range: [-1e+20,1e+20], default: 1.3]
branching/pscost/maxscoreweight = 1.3

# weight for sum of scores of a branching candidate when building weighted sum of min/max/sum of scores
# [type: real, advanced: TRUE, range: [-1e+20,1e+20], default: 0.1]
branching/pscost/sumscoreweight = 0.1

# number of children to create in n-ary branching
# [type: int, advanced: FALSE, range: [2,2147483647], default: 2]
branching/pscost/nchildren = 2

# maximal depth where to do n-ary branching, -1 to turn off
# [type: int, advanced: FALSE, range: [-1,2147483647], default: -1]
branching/pscost/narymaxdepth = -1

# minimal domain width in children when doing n-ary branching, relative to global bounds
# [type: real, advanced: FALSE, range: [0,1], default: 0.001]
branching/pscost/naryminwidth = 0.001

# factor of domain width in n-ary branching when creating nodes with increasing distance from branching value
# [type: real, advanced: FALSE, range: [1,1.79769313486232e+308], default: 2]
branching/pscost/narywidthfactor = 2

# priority of branching rule <random>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: -100000]
branching/random/priority = -100000

# maximal depth level, up to which branching rule <random> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/random/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/random/maxbounddist = 1

# initial random seed value
# [type: int, advanced: FALSE, range: [0,2147483647], default: 41]
branching/random/seed = 41

# priority of branching rule <relpscost>
# [type: int, advanced: FALSE, range: [-536870912,536870911], default: 10000]
branching/relpscost/priority = 10000

# maximal depth level, up to which branching rule <relpscost> should be used (-1 for no limit)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
branching/relpscost/maxdepth = -1

# maximal relative distance from current node's dual bound to primal bound compared to best node's dual bound for applying branching rule (0.0: only on current best node, 1.0: on all nodes)
# [type: real, advanced: FALSE, range: [0,1], default: 1]
branching/relpscost/maxbounddist = 1

# weight in score calculations for conflict score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0.01]
branching/relpscost/conflictweight = 0.01

# weight in score calculations for conflict length score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0]
branching/relpscost/conflictlengthweight = 0

# weight in score calculations for inference score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0.0001]
branching/relpscost/inferenceweight = 0.0001

# weight in score calculations for cutoff score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0.0001]
branching/relpscost/cutoffweight = 0.0001

# weight in score calculations for pseudo cost score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1]
branching/relpscost/pscostweight = 1

# weight in score calculations for nlcount score
# [type: real, advanced: TRUE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 0.1]
branching/relpscost/nlscoreweight = 0.1

# minimal value for minimum pseudo cost size to regard pseudo cost value as reliable
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1]
branching/relpscost/minreliable = 1

# maximal value for minimum pseudo cost size to regard pseudo cost value as reliable
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 5]
branching/relpscost/maxreliable = 5

# maximal fraction of strong branching LP iterations compared to node relaxation LP iterations
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 0.5]
branching/relpscost/sbiterquot = 0.5

# additional number of allowed strong branching LP iterations
# [type: int, advanced: FALSE, range: [0,2147483647], default: 100000]
branching/relpscost/sbiterofs = 100000

# maximal number of further variables evaluated without better score
# [type: int, advanced: TRUE, range: [1,2147483647], default: 9]
branching/relpscost/maxlookahead = 9

# maximal number of candidates initialized with strong branching per node
# [type: int, advanced: FALSE, range: [0,2147483647], default: 100]
branching/relpscost/initcand = 100

# iteration limit for strong branching initializations of pseudo cost entries (0: auto)
# [type: int, advanced: FALSE, range: [0,2147483647], default: 0]
branching/relpscost/inititer = 0

# maximal number of bound tightenings before the node is reevaluated (-1: unlimited)
# [type: int, advanced: TRUE, range: [-1,2147483647], default: 5]
branching/relpscost/maxbdchgs = 5

# maximum number of propagation rounds to be performed during strong branching before solving the LP (-1: no limit, -2: parameter settings)
# [type: int, advanced: TRUE, range: [-2,2147483647], default: -2]
branching/relpscost/maxproprounds = -2

# should valid bounds be identified in a probing-like fashion during strong branching (only with propagation)?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/relpscost/probingbounds = TRUE

# should reliability be based on relative errors?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/userelerrorreliability = FALSE

# low relative error tolerance for reliability
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 0.05]
branching/relpscost/lowerrortol = 0.05

# high relative error tolerance for reliability
# [type: real, advanced: TRUE, range: [0,1.79769313486232e+308], default: 1]
branching/relpscost/higherrortol = 1

# should strong branching result be considered for pseudo costs if the other direction was infeasible?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/storesemiinitcosts = FALSE

# should the scoring function use only local cutoff and inference information obtained for strong branching candidates?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/usesblocalinfo = FALSE

# should the strong branching decision be based on a hypothesis test?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/usehyptestforreliability = FALSE

# should the confidence level be adjusted dynamically?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/usedynamicconfidence = FALSE

# should branching rule skip candidates that have a low probability to be better than the best strong-branching or pseudo-candidate?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/relpscost/skipbadinitcands = TRUE

# the confidence level for statistical methods, between 0 (Min) and 4 (Max).
# [type: int, advanced: TRUE, range: [0,4], default: 2]
branching/relpscost/confidencelevel = 2

# should candidates be initialized in randomized order?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/randinitorder = FALSE

# should smaller weights be used for pseudo cost updates after hitting the LP iteration limit?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: FALSE]
branching/relpscost/usesmallweightsitlim = FALSE

# should the weights of the branching rule be adjusted dynamically during solving based on objective and infeasible leaf counters?
# [type: bool, advanced: TRUE, range: {TRUE,FALSE}, default: TRUE]
branching/relpscost/dynamicweights = TRUE

# start seed for random number generation
# [type: int, advanced: TRUE, range: [0,2147483647], default: 5]
branching/relpscost/startrandseed = 5

# display activation status of display column <nrank1nodes> (0: off, 1: auto, 2:on)
# [type: int, advanced: FALSE, range: [0,2], default: 0]
display/nrank1nodes/active = 0

# display activation status of display column <nnodesbelowinc> (0: off, 1: auto, 2:on)
# [type: int, advanced: FALSE, range: [0,2], default: 0]
display/nnodesbelowinc/active = 0

# should the event handler adapt the solver behavior?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/enabled = FALSE

# should the event handler test all phase transitions?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/testmode = FALSE

# settings file for feasibility phase -- precedence over emphasis settings
# [type: string, advanced: FALSE, default: "-"]
solvingphases/feassetname = "-"

# settings file for improvement phase -- precedence over emphasis settings
# [type: string, advanced: FALSE, default: "-"]
solvingphases/improvesetname = "-"

# settings file for proof phase -- precedence over emphasis settings
# [type: string, advanced: FALSE, default: "-"]
solvingphases/proofsetname = "-"

# node offset for rank-1 and estimate transitions
# [type: longint, advanced: FALSE, range: [1,9223372036854775807], default: 50]
solvingphases/nodeoffset = 50

# should the event handler fall back from optimal phase?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/fallback = FALSE

# transition method: Possible options are 'e'stimate,'l'ogarithmic regression,'o'ptimal-value based,'r'ank-1
# [type: char, advanced: FALSE, range: {elor}, default: r]
solvingphases/transitionmethod = r

# should the event handler interrupt the solving process after optimal solution was found?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/interruptoptimal = FALSE

# should a restart be applied between the feasibility and improvement phase?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/userestart1to2 = FALSE

# should a restart be applied between the improvement and the proof phase?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
solvingphases/userestart2to3 = FALSE

# optimal solution value for problem
# [type: real, advanced: FALSE, range: [-1.79769313486232e+308,1.79769313486232e+308], default: 1e+99]
solvingphases/optimalvalue = 1e+99

# x-type for logarithmic regression - (t)ime, (n)odes, (l)p iterations
# [type: char, advanced: FALSE, range: {lnt}, default: n]
solvingphases/xtype = n

# should emphasis settings for the solving phases be used, or settings files?
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: TRUE]
solvingphases/useemphsettings = TRUE

# priority of compression <largestrepr>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 2000]
compression/largestrepr/priority = 2000

# minimal number of leave nodes for calling tree compression <largestrepr>
# [type: int, advanced: FALSE, range: [1,2147483647], default: 20]
compression/largestrepr/minnleaves = 20

# number of runs in the constrained part.
# [type: int, advanced: FALSE, range: [1,2147483647], default: 5]
compression/largestrepr/iterations = 5

# minimal number of common variables.
# [type: int, advanced: FALSE, range: [1,2147483647], default: 3]
compression/largestrepr/mincommonvars = 3

# priority of compression <weakcompr>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: 1000]
compression/weakcompr/priority = 1000

# minimal number of leave nodes for calling tree compression <weakcompr>
# [type: int, advanced: FALSE, range: [1,2147483647], default: 50]
compression/weakcompr/minnleaves = 50

# convert constraints into nodes
# [type: bool, advanced: FALSE, range: {TRUE,FALSE}, default: FALSE]
compression/weakcompr/convertconss = FALSE

# priority of heuristic <actconsdiving>
# [type: int, advanced: TRUE, range: [-536870912,536870911], default: -1003700]
heuristics/actconsdiving/priority = -1003700

# frequency for calling primal heuristic <actconsdiving> (-1: never, 0: only at depth freqofs)
# [type: int, advanced: FALSE, range: [-1,65534], default: -1]
heuristics/actconsdiving/freq = -1

# frequency offset for calling primal heuristic <actconsdiving>
# [type: int, advanced: FALSE, range: [0,65534], default: 5]
heuristics/actconsdiving/freqofs = 5

# maximal depth level to call primal heuristic <actconsdiving> (-1: no limit)
# [type: int, advanced: TRUE, range: [-1,65534], default: -1]
heuristics/actconsdiving/maxdepth = -1

# minimal relative depth to start diving
# [type: real, advanced: TRUE, range: [0,1], default: 0]
heuristics/actconsdiving/minreldepth = 0

# maximal relative depth to start diving
# [type: real, advanced: TRUE, range: [0,1], default: 1]
heuristics/actconsdiving/maxreldepth = 1

# maximal fraction of diving LP iterations compared to node LP iterations
# [type: real, advanced: FALSE, range: [0,1.79769313486232e+308], default: 0.05]
heuristics/actconsdiving/maxlpiterquot = 0.05

# additional number of allowed LP iterations
# [type: int, advanced: FALSE, range: [0,2147483647], default: 1000]
heuristics/actconsdiving/maxlpiterofs = 1000

# maximal quotient (curlowerbound - lowerbound)/(cutof